{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cff0e66e",
   "metadata": {},
   "source": [
    "# Goal\n",
    "It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83da61d8",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11dd2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "import pandas as pd \n",
    "train = pd.read_csv(\"C:/Users/Arshadali Shaikh/Downloads/training_set (1).csv\")\n",
    "test = pd.read_csv(\"C:/Users/Arshadali Shaikh/Downloads/testing_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f5952b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64daf762",
   "metadata": {},
   "source": [
    "# Missing Data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f27671a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "MSSubClass         0\n",
       "MSZoning           0\n",
       "LotFrontage      259\n",
       "LotArea            0\n",
       "                ... \n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SaleType           0\n",
       "SaleCondition      0\n",
       "SalePrice          0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a116f",
   "metadata": {},
   "source": [
    "# there are many values which contains NA which uses as a shortform so i have fill the rows with that original name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b910b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Alley = train.Alley.fillna(\"No alley access\")\n",
    "train.BsmtQual = train.BsmtQual.fillna(\"No Basement\")\n",
    "train.BsmtCond = train.BsmtCond.fillna(\"No Basement\")\n",
    "train.BsmtExposure = train.BsmtExposure.fillna(\"No Basement\")\n",
    "train.BsmtFinType1 = train.BsmtFinType1.fillna(\"No Basement\")\n",
    "train.BsmtFinType2 = train.BsmtFinType2.fillna(\"No Basement\")\n",
    "train.FireplaceQu = train.FireplaceQu.fillna(\"No Fireplace\")\n",
    "train.GarageType = train.GarageType.fillna(\"No Garage\")\n",
    "train.GarageFinish = train.GarageFinish.fillna(\"No Garage\")\n",
    "train.GarageQual = train.GarageQual.fillna(\"No Garage\")\n",
    "train.GarageCond = train.GarageCond.fillna(\"No Garage\")\n",
    "train.PoolQC = train.PoolQC.fillna(\"No Pool\")\n",
    "train.Fence = train.Fence.fillna(\"No Fence\")\n",
    "train.MiscFeature = train.MiscFeature.fillna(\"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35be2694",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Alley = test.Alley.fillna(\"No alley access\")\n",
    "test.BsmtQual = test.BsmtQual.fillna(\"No Basement\")\n",
    "test.BsmtCond = test.BsmtCond.fillna(\"No Basement\")\n",
    "test.BsmtExposure = test.BsmtExposure.fillna(\"No Basement\")\n",
    "test.BsmtFinType1 = test.BsmtFinType1.fillna(\"No Basement\")\n",
    "test.BsmtFinType2 = test.BsmtFinType2.fillna(\"No Basement\")\n",
    "test.FireplaceQu = test.FireplaceQu.fillna(\"No Fireplace\")\n",
    "test.GarageType = test.GarageType.fillna(\"No Garage\")\n",
    "test.GarageFinish = test.GarageFinish.fillna(\"No Garage\")\n",
    "test.GarageQual = test.GarageQual.fillna(\"No Garage\")\n",
    "test.GarageCond = test.GarageCond.fillna(\"No Garage\")\n",
    "test.PoolQC = test.PoolQC.fillna(\"No Pool\")\n",
    "test.Fence = test.Fence.fillna(\"No Fence\")\n",
    "test.MiscFeature = test.MiscFeature.fillna(\"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014537e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(df):\n",
    "    for i in df.columns:\n",
    "        if(df[i].dtypes == \"object\"):\n",
    "            x = df[i].mode()[0]\n",
    "            df[i]=df[i].fillna(x)\n",
    "        else:\n",
    "            x = df[i].mean()\n",
    "            df[i]=df[i].fillna(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7225a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacer(train)\n",
    "replacer(test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d6a2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               0\n",
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()  #removed missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a00516",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a68d288e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KitchenAbvGr    -0.135907\n",
       "EnclosedPorch   -0.128578\n",
       "MSSubClass      -0.084284\n",
       "OverallCond     -0.077856\n",
       "YrSold          -0.028923\n",
       "LowQualFinSF    -0.025606\n",
       "Id              -0.021917\n",
       "MiscVal         -0.021190\n",
       "BsmtHalfBath    -0.016844\n",
       "BsmtFinSF2      -0.011378\n",
       "3SsnPorch        0.044584\n",
       "MoSold           0.046432\n",
       "PoolArea         0.092404\n",
       "ScreenPorch      0.111447\n",
       "BedroomAbvGr     0.168213\n",
       "BsmtUnfSF        0.214479\n",
       "BsmtFullBath     0.227122\n",
       "LotArea          0.263843\n",
       "HalfBath         0.284108\n",
       "OpenPorchSF      0.315856\n",
       "2ndFlrSF         0.319334\n",
       "WoodDeckSF       0.324413\n",
       "LotFrontage      0.334901\n",
       "BsmtFinSF1       0.386420\n",
       "Fireplaces       0.466929\n",
       "GarageYrBlt      0.470177\n",
       "MasVnrArea       0.475241\n",
       "YearRemodAdd     0.507101\n",
       "YearBuilt        0.522897\n",
       "TotRmsAbvGrd     0.533723\n",
       "FullBath         0.560664\n",
       "1stFlrSF         0.605852\n",
       "TotalBsmtSF      0.613581\n",
       "GarageArea       0.623431\n",
       "GarageCars       0.640409\n",
       "GrLivArea        0.708624\n",
       "OverallQual      0.790982\n",
       "SalePrice        1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = train[[\"SalePrice\"]]\n",
    "X = train.drop(labels=[\"Id\",\"SalePrice\"],axis=1)\n",
    "from PM8 import ANOVA\n",
    "train.corr()[\"SalePrice\"].sort_values()  #find out the correlation of the column and then sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c0a6317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street            Alley  \\\n",
       "0             60       RL         65.0     8450   Pave  No alley access   \n",
       "1             20       RL         80.0     9600   Pave  No alley access   \n",
       "2             60       RL         68.0    11250   Pave  No alley access   \n",
       "3             70       RL         60.0     9550   Pave  No alley access   \n",
       "4             60       RL         84.0    14260   Pave  No alley access   \n",
       "...          ...      ...          ...      ...    ...              ...   \n",
       "1455          60       RL         62.0     7917   Pave  No alley access   \n",
       "1456          20       RL         85.0    13175   Pave  No alley access   \n",
       "1457          70       RL         66.0     9042   Pave  No alley access   \n",
       "1458          20       RL         68.0     9717   Pave  No alley access   \n",
       "1459          20       RL         75.0     9937   Pave  No alley access   \n",
       "\n",
       "     LotShape LandContour Utilities LotConfig  ... ScreenPorch PoolArea  \\\n",
       "0         Reg         Lvl    AllPub    Inside  ...           0        0   \n",
       "1         Reg         Lvl    AllPub       FR2  ...           0        0   \n",
       "2         IR1         Lvl    AllPub    Inside  ...           0        0   \n",
       "3         IR1         Lvl    AllPub    Corner  ...           0        0   \n",
       "4         IR1         Lvl    AllPub       FR2  ...           0        0   \n",
       "...       ...         ...       ...       ...  ...         ...      ...   \n",
       "1455      Reg         Lvl    AllPub    Inside  ...           0        0   \n",
       "1456      Reg         Lvl    AllPub    Inside  ...           0        0   \n",
       "1457      Reg         Lvl    AllPub    Inside  ...           0        0   \n",
       "1458      Reg         Lvl    AllPub    Inside  ...           0        0   \n",
       "1459      Reg         Lvl    AllPub    Inside  ...           0        0   \n",
       "\n",
       "       PoolQC     Fence MiscFeature MiscVal  MoSold  YrSold  SaleType  \\\n",
       "0     No Pool  No Fence        None       0       2    2008        WD   \n",
       "1     No Pool  No Fence        None       0       5    2007        WD   \n",
       "2     No Pool  No Fence        None       0       9    2008        WD   \n",
       "3     No Pool  No Fence        None       0       2    2006        WD   \n",
       "4     No Pool  No Fence        None       0      12    2008        WD   \n",
       "...       ...       ...         ...     ...     ...     ...       ...   \n",
       "1455  No Pool  No Fence        None       0       8    2007        WD   \n",
       "1456  No Pool     MnPrv        None       0       2    2010        WD   \n",
       "1457  No Pool     GdPrv        Shed    2500       5    2010        WD   \n",
       "1458  No Pool  No Fence        None       0       4    2010        WD   \n",
       "1459  No Pool  No Fence        None       0       6    2008        WD   \n",
       "\n",
       "      SaleCondition  \n",
       "0            Normal  \n",
       "1            Normal  \n",
       "2            Normal  \n",
       "3           Abnorml  \n",
       "4            Normal  \n",
       "...             ...  \n",
       "1455         Normal  \n",
       "1456         Normal  \n",
       "1457         Normal  \n",
       "1458         Normal  \n",
       "1459         Normal  \n",
       "\n",
       "[1460 rows x 79 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3293230b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalePrice vs  MSZoning :----> 0.0\n",
      "SalePrice vs  Street :----> 0.117\n",
      "SalePrice vs  Alley :----> 0.0\n",
      "SalePrice vs  LotShape :----> 0.0\n",
      "SalePrice vs  LandContour :----> 0.0\n",
      "SalePrice vs  Utilities :----> 0.585\n",
      "SalePrice vs  LotConfig :----> 0.0\n",
      "SalePrice vs  LandSlope :----> 0.141\n",
      "SalePrice vs  Neighborhood :----> 0.0\n",
      "SalePrice vs  Condition1 :----> 0.0\n",
      "SalePrice vs  Condition2 :----> 0.043\n",
      "SalePrice vs  BldgType :----> 0.0\n",
      "SalePrice vs  HouseStyle :----> 0.0\n",
      "SalePrice vs  RoofStyle :----> 0.0\n",
      "SalePrice vs  RoofMatl :----> 0.0\n",
      "SalePrice vs  Exterior1st :----> 0.0\n",
      "SalePrice vs  Exterior2nd :----> 0.0\n",
      "SalePrice vs  MasVnrType :----> 0.0\n",
      "SalePrice vs  ExterQual :----> 0.0\n",
      "SalePrice vs  ExterCond :----> 0.0\n",
      "SalePrice vs  Foundation :----> 0.0\n",
      "SalePrice vs  BsmtQual :----> 0.0\n",
      "SalePrice vs  BsmtCond :----> 0.0\n",
      "SalePrice vs  BsmtExposure :----> 0.0\n",
      "SalePrice vs  BsmtFinType1 :----> 0.0\n",
      "SalePrice vs  BsmtFinType2 :----> 0.0\n",
      "SalePrice vs  Heating :----> 0.001\n",
      "SalePrice vs  HeatingQC :----> 0.0\n",
      "SalePrice vs  CentralAir :----> 0.0\n",
      "SalePrice vs  Electrical :----> 0.0\n",
      "SalePrice vs  KitchenQual :----> 0.0\n",
      "SalePrice vs  Functional :----> 0.0\n",
      "SalePrice vs  FireplaceQu :----> 0.0\n",
      "SalePrice vs  GarageType :----> 0.0\n",
      "SalePrice vs  GarageFinish :----> 0.0\n",
      "SalePrice vs  GarageQual :----> 0.0\n",
      "SalePrice vs  GarageCond :----> 0.0\n",
      "SalePrice vs  PavedDrive :----> 0.0\n",
      "SalePrice vs  PoolQC :----> 0.0\n",
      "SalePrice vs  Fence :----> 0.0\n",
      "SalePrice vs  MiscFeature :----> 0.035\n",
      "SalePrice vs  SaleType :----> 0.0\n",
      "SalePrice vs  SaleCondition :----> 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in train.columns:\n",
    "    if(train[i].dtypes == \"object\"):\n",
    "        print(\"SalePrice vs \",i,\":---->\",ANOVA(train,i,\"SalePrice\"))  \n",
    "        \n",
    "# find the pvalues to know the statiscally feature importance for target varaible by usnig Anova Function. \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02472435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(labels=[\"Street\",\"Utilities\"],axis=1) # no importance features so dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16612d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NWAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>No alley access</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Pool</td>\n",
       "      <td>No Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea            Alley LotShape  \\\n",
       "0             60       RL         65.0     8450  No alley access      Reg   \n",
       "1             20       RL         80.0     9600  No alley access      Reg   \n",
       "2             60       RL         68.0    11250  No alley access      IR1   \n",
       "3             70       RL         60.0     9550  No alley access      IR1   \n",
       "4             60       RL         84.0    14260  No alley access      IR1   \n",
       "...          ...      ...          ...      ...              ...      ...   \n",
       "1455          60       RL         62.0     7917  No alley access      Reg   \n",
       "1456          20       RL         85.0    13175  No alley access      Reg   \n",
       "1457          70       RL         66.0     9042  No alley access      Reg   \n",
       "1458          20       RL         68.0     9717  No alley access      Reg   \n",
       "1459          20       RL         75.0     9937  No alley access      Reg   \n",
       "\n",
       "     LandContour LotConfig LandSlope Neighborhood  ... ScreenPorch PoolArea  \\\n",
       "0            Lvl    Inside       Gtl      CollgCr  ...           0        0   \n",
       "1            Lvl       FR2       Gtl      Veenker  ...           0        0   \n",
       "2            Lvl    Inside       Gtl      CollgCr  ...           0        0   \n",
       "3            Lvl    Corner       Gtl      Crawfor  ...           0        0   \n",
       "4            Lvl       FR2       Gtl      NoRidge  ...           0        0   \n",
       "...          ...       ...       ...          ...  ...         ...      ...   \n",
       "1455         Lvl    Inside       Gtl      Gilbert  ...           0        0   \n",
       "1456         Lvl    Inside       Gtl       NWAmes  ...           0        0   \n",
       "1457         Lvl    Inside       Gtl      Crawfor  ...           0        0   \n",
       "1458         Lvl    Inside       Gtl        NAmes  ...           0        0   \n",
       "1459         Lvl    Inside       Gtl      Edwards  ...           0        0   \n",
       "\n",
       "       PoolQC     Fence  MiscFeature  MiscVal  MoSold  YrSold SaleType  \\\n",
       "0     No Pool  No Fence         None        0       2    2008       WD   \n",
       "1     No Pool  No Fence         None        0       5    2007       WD   \n",
       "2     No Pool  No Fence         None        0       9    2008       WD   \n",
       "3     No Pool  No Fence         None        0       2    2006       WD   \n",
       "4     No Pool  No Fence         None        0      12    2008       WD   \n",
       "...       ...       ...          ...      ...     ...     ...      ...   \n",
       "1455  No Pool  No Fence         None        0       8    2007       WD   \n",
       "1456  No Pool     MnPrv         None        0       2    2010       WD   \n",
       "1457  No Pool     GdPrv         Shed     2500       5    2010       WD   \n",
       "1458  No Pool  No Fence         None        0       4    2010       WD   \n",
       "1459  No Pool  No Fence         None        0       6    2008       WD   \n",
       "\n",
       "     SaleCondition  \n",
       "0           Normal  \n",
       "1           Normal  \n",
       "2           Normal  \n",
       "3          Abnorml  \n",
       "4           Normal  \n",
       "...            ...  \n",
       "1455        Normal  \n",
       "1456        Normal  \n",
       "1457        Normal  \n",
       "1458        Normal  \n",
       "1459        Normal  \n",
       "\n",
       "[1460 rows x 77 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7c97d",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "729d41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    import pandas as pd\n",
    "    cat = []\n",
    "    con = []\n",
    "    for i in df.columns:\n",
    "        if(df[i].dtypes == \"object\"):\n",
    "            cat.append(i)\n",
    "        else:\n",
    "            con.append(i)\n",
    "    X1 = pd.get_dummies(df[cat])\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    ss = StandardScaler()\n",
    "    X2 = pd.DataFrame(ss.fit_transform(df[con]),columns=con)\n",
    "    X3 = X2.join(X1)\n",
    "    return X3\n",
    "\n",
    "Xnew = preprocessing(X)   #preprocessed the data to make data in a same scale.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9577eaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073375</td>\n",
       "      <td>-0.229372</td>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.878668</td>\n",
       "      <td>0.511418</td>\n",
       "      <td>0.575425</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.872563</td>\n",
       "      <td>0.451936</td>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>2.179628</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>-0.574410</td>\n",
       "      <td>1.171992</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073375</td>\n",
       "      <td>-0.093110</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.984752</td>\n",
       "      <td>0.830215</td>\n",
       "      <td>0.323060</td>\n",
       "      <td>0.092907</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.309859</td>\n",
       "      <td>-0.456474</td>\n",
       "      <td>-0.096897</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-1.863632</td>\n",
       "      <td>-0.720298</td>\n",
       "      <td>-0.574410</td>\n",
       "      <td>-0.499274</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073375</td>\n",
       "      <td>0.633618</td>\n",
       "      <td>0.375148</td>\n",
       "      <td>1.374795</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.951632</td>\n",
       "      <td>0.733308</td>\n",
       "      <td>1.364570</td>\n",
       "      <td>0.463568</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.073375</td>\n",
       "      <td>-0.365633</td>\n",
       "      <td>-0.260560</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.918511</td>\n",
       "      <td>0.733308</td>\n",
       "      <td>-0.574410</td>\n",
       "      <td>-0.973018</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>-0.872563</td>\n",
       "      <td>0.679039</td>\n",
       "      <td>0.266407</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.381743</td>\n",
       "      <td>0.222975</td>\n",
       "      <td>0.151865</td>\n",
       "      <td>0.084843</td>\n",
       "      <td>0.759659</td>\n",
       "      <td>0.722112</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.309859</td>\n",
       "      <td>-0.183951</td>\n",
       "      <td>-0.147810</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>3.078570</td>\n",
       "      <td>-1.002492</td>\n",
       "      <td>1.024029</td>\n",
       "      <td>-0.574410</td>\n",
       "      <td>-0.369871</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>-0.872563</td>\n",
       "      <td>-0.093110</td>\n",
       "      <td>-0.080160</td>\n",
       "      <td>-0.795151</td>\n",
       "      <td>0.381743</td>\n",
       "      <td>-0.704406</td>\n",
       "      <td>0.539493</td>\n",
       "      <td>-0.574410</td>\n",
       "      <td>-0.865548</td>\n",
       "      <td>6.092188</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>-0.872563</td>\n",
       "      <td>0.224833</td>\n",
       "      <td>-0.058112</td>\n",
       "      <td>-0.795151</td>\n",
       "      <td>0.381743</td>\n",
       "      <td>-0.207594</td>\n",
       "      <td>-0.962566</td>\n",
       "      <td>-0.574410</td>\n",
       "      <td>0.847389</td>\n",
       "      <td>1.509640</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       0.073375    -0.229372 -0.207142     0.651479    -0.517200   1.050994   \n",
       "1      -0.872563     0.451936 -0.091886    -0.071836     2.179628   0.156734   \n",
       "2       0.073375    -0.093110  0.073480     0.651479    -0.517200   0.984752   \n",
       "3       0.309859    -0.456474 -0.096897     0.651479    -0.517200  -1.863632   \n",
       "4       0.073375     0.633618  0.375148     1.374795    -0.517200   0.951632   \n",
       "...          ...          ...       ...          ...          ...        ...   \n",
       "1455    0.073375    -0.365633 -0.260560    -0.071836    -0.517200   0.918511   \n",
       "1456   -0.872563     0.679039  0.266407    -0.071836     0.381743   0.222975   \n",
       "1457    0.309859    -0.183951 -0.147810     0.651479     3.078570  -1.002492   \n",
       "1458   -0.872563    -0.093110 -0.080160    -0.795151     0.381743  -0.704406   \n",
       "1459   -0.872563     0.224833 -0.058112    -0.795151     0.381743  -0.207594   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLw  \\\n",
       "0         0.878668    0.511418    0.575425   -0.288653  ...               0   \n",
       "1        -0.429577   -0.574410    1.171992   -0.288653  ...               0   \n",
       "2         0.830215    0.323060    0.092907   -0.288653  ...               0   \n",
       "3        -0.720298   -0.574410   -0.499274   -0.288653  ...               0   \n",
       "4         0.733308    1.364570    0.463568   -0.288653  ...               0   \n",
       "...            ...         ...         ...         ...  ...             ...   \n",
       "1455      0.733308   -0.574410   -0.973018   -0.288653  ...               0   \n",
       "1456      0.151865    0.084843    0.759659    0.722112  ...               0   \n",
       "1457      1.024029   -0.574410   -0.369871   -0.288653  ...               0   \n",
       "1458      0.539493   -0.574410   -0.865548    6.092188  ...               0   \n",
       "1459     -0.962566   -0.574410    0.847389    1.509640  ...               0   \n",
       "\n",
       "      SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
       "0                0             0            1                      0   \n",
       "1                0             0            1                      0   \n",
       "2                0             0            1                      0   \n",
       "3                0             0            1                      1   \n",
       "4                0             0            1                      0   \n",
       "...            ...           ...          ...                    ...   \n",
       "1455             0             0            1                      0   \n",
       "1456             0             0            1                      0   \n",
       "1457             0             0            1                      0   \n",
       "1458             0             0            1                      0   \n",
       "1459             0             0            1                      0   \n",
       "\n",
       "      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "1455                      0                     0                     0   \n",
       "1456                      0                     0                     0   \n",
       "1457                      0                     0                     0   \n",
       "1458                      0                     0                     0   \n",
       "1459                      0                     0                     0   \n",
       "\n",
       "      SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                        1                      0  \n",
       "1                        1                      0  \n",
       "2                        1                      0  \n",
       "3                        0                      0  \n",
       "4                        1                      0  \n",
       "...                    ...                    ...  \n",
       "1455                     1                      0  \n",
       "1456                     1                      0  \n",
       "1457                     1                      0  \n",
       "1458                     1                      0  \n",
       "1459                     1                      0  \n",
       "\n",
       "[1460 rows x 298 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaf7bca",
   "metadata": {},
   "source": [
    "# Splitting Data in Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a698ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xval,ytrain,yval = train_test_split(Xnew,Y,test_size=0.20,random_state=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4258872a",
   "metadata": {},
   "source": [
    "# Model OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "396c5a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import add_constant,OLS\n",
    "xconst = add_constant(xtrain)\n",
    "ols = OLS(ytrain,xconst)\n",
    "model = ols.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c180d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous: 0.93321 \tCurrent: 0.93328 \t MSSubClass\n"
     ]
    }
   ],
   "source": [
    "prev_rsq = model.rsquared_adj\n",
    "col_to_drop = model.pvalues.sort_values().tail(1).index[0]\n",
    "Xnew = Xnew.drop(labels=col_to_drop,axis=1)\n",
    "xtrain,xval,ytrain,yval = train_test_split(Xnew,Y,test_size=0.2,random_state=31)\n",
    "xconst = add_constant(xtrain)\n",
    "ols = OLS(ytrain,xconst)\n",
    "model = ols.fit()\n",
    "curr_rsq = model.rsquared_adj\n",
    "print(\"Previous:\",round(prev_rsq,5),\"\\tCurrent:\",round(curr_rsq,5),\"\\t\",col_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918691bc",
   "metadata": {},
   "source": [
    "# train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a3ef3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(xtrain,ytrain)\n",
    "pred_tr = model.predict(xtrain)\n",
    "pred_ts = model.predict(xval)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "tr_err = mean_absolute_error(ytrain,pred_tr)\n",
    "ts_err = mean_absolute_error(yval,pred_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9190d314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12555.440924657534"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78ddd7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514594962236640.1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c5d573",
   "metadata": {},
   "source": [
    "# Regularize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81c0bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "def reg(mo):\n",
    "    model = mo.fit(xtrain,ytrain)\n",
    "    pred_tr = model.predict(xtrain)\n",
    "    pred_ts = model.predict(xval)\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    tr_err = mean_absolute_error(ytrain,pred_tr)\n",
    "    ts_err = mean_absolute_error(yval,pred_ts)\n",
    "    print(\"Training Error\",tr_err)\n",
    "    print(\"Testing Error\",ts_err)\n",
    "    print(\"--------------------\")\n",
    "    return ts_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "300a3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = []\n",
    "e =0.0\n",
    "for i in range(0,1000):\n",
    "    W.append(round(e,3))\n",
    "    e = e+0.001\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7cf15b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "730f8738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Alpha 0.0 ---------\n",
      "Training Error 15276.016267123288\n",
      "Testing Error 2.0671908949531056e+16\n",
      "--------------------\n",
      "---------- Alpha 0.001 ---------\n",
      "Training Error 12419.51139267053\n",
      "Testing Error 18291.010393916928\n",
      "--------------------\n",
      "---------- Alpha 0.002 ---------\n",
      "Training Error 12419.862811681835\n",
      "Testing Error 18289.653750437712\n",
      "--------------------\n",
      "---------- Alpha 0.003 ---------\n",
      "Training Error 12420.251375678838\n",
      "Testing Error 18288.302392483834\n",
      "--------------------\n",
      "---------- Alpha 0.004 ---------\n",
      "Training Error 12420.704112927771\n",
      "Testing Error 18286.956280212682\n",
      "--------------------\n",
      "---------- Alpha 0.005 ---------\n",
      "Training Error 12421.172735806153\n",
      "Testing Error 18285.61534872424\n",
      "--------------------\n",
      "---------- Alpha 0.006 ---------\n",
      "Training Error 12421.638718569864\n",
      "Testing Error 18284.279515245395\n",
      "--------------------\n",
      "---------- Alpha 0.007 ---------\n",
      "Training Error 12422.089582180068\n",
      "Testing Error 18282.948684659186\n",
      "--------------------\n",
      "---------- Alpha 0.008 ---------\n",
      "Training Error 12422.526063358851\n",
      "Testing Error 18281.622753703723\n",
      "--------------------\n",
      "---------- Alpha 0.009 ---------\n",
      "Training Error 12423.020004650441\n",
      "Testing Error 18280.301614193886\n",
      "--------------------\n",
      "---------- Alpha 0.01 ---------\n",
      "Training Error 12423.519264475433\n",
      "Testing Error 18278.98515546239\n",
      "--------------------\n",
      "---------- Alpha 0.011 ---------\n",
      "Training Error 12424.037237448494\n",
      "Testing Error 18277.6732662172\n",
      "--------------------\n",
      "---------- Alpha 0.012 ---------\n",
      "Training Error 12424.566692392951\n",
      "Testing Error 18276.36583592484\n",
      "--------------------\n",
      "---------- Alpha 0.013 ---------\n",
      "Training Error 12425.087696250404\n",
      "Testing Error 18275.123458834685\n",
      "--------------------\n",
      "---------- Alpha 0.014 ---------\n",
      "Training Error 12425.597779931188\n",
      "Testing Error 18274.220598093816\n",
      "--------------------\n",
      "---------- Alpha 0.015 ---------\n",
      "Training Error 12426.15136243585\n",
      "Testing Error 18273.317830992684\n",
      "--------------------\n",
      "---------- Alpha 0.016 ---------\n",
      "Training Error 12426.746756758466\n",
      "Testing Error 18272.41520505242\n",
      "--------------------\n",
      "---------- Alpha 0.017 ---------\n",
      "Training Error 12427.330762384065\n",
      "Testing Error 18271.51275996512\n",
      "--------------------\n",
      "---------- Alpha 0.018 ---------\n",
      "Training Error 12427.903750450883\n",
      "Testing Error 18270.610528948175\n",
      "--------------------\n",
      "---------- Alpha 0.019 ---------\n",
      "Training Error 12428.466070772301\n",
      "Testing Error 18269.708539869484\n",
      "--------------------\n",
      "---------- Alpha 0.02 ---------\n",
      "Training Error 12429.018053559732\n",
      "Testing Error 18268.80681618137\n",
      "--------------------\n",
      "---------- Alpha 0.021 ---------\n",
      "Training Error 12429.560010973068\n",
      "Testing Error 18267.9053776961\n",
      "--------------------\n",
      "---------- Alpha 0.022 ---------\n",
      "Training Error 12430.092238518968\n",
      "Testing Error 18267.004241232335\n",
      "--------------------\n",
      "---------- Alpha 0.023 ---------\n",
      "Training Error 12430.615016314508\n",
      "Testing Error 18266.103421150783\n",
      "--------------------\n",
      "---------- Alpha 0.024 ---------\n",
      "Training Error 12431.128610231317\n",
      "Testing Error 18265.202929803345\n",
      "--------------------\n",
      "---------- Alpha 0.025 ---------\n",
      "Training Error 12431.633272933368\n",
      "Testing Error 18264.30277790366\n",
      "--------------------\n",
      "---------- Alpha 0.026 ---------\n",
      "Training Error 12432.135778100568\n",
      "Testing Error 18263.637454599957\n",
      "--------------------\n",
      "---------- Alpha 0.027 ---------\n",
      "Training Error 12432.671087785175\n",
      "Testing Error 18262.999458229635\n",
      "--------------------\n",
      "---------- Alpha 0.028 ---------\n",
      "Training Error 12433.204771830979\n",
      "Testing Error 18262.39153832452\n",
      "--------------------\n",
      "---------- Alpha 0.029 ---------\n",
      "Training Error 12433.730861672992\n",
      "Testing Error 18262.012244738304\n",
      "--------------------\n",
      "---------- Alpha 0.03 ---------\n",
      "Training Error 12434.249536579857\n",
      "Testing Error 18261.629257745626\n",
      "--------------------\n",
      "---------- Alpha 0.031 ---------\n",
      "Training Error 12434.780873363652\n",
      "Testing Error 18261.242664674195\n",
      "--------------------\n",
      "---------- Alpha 0.032 ---------\n",
      "Training Error 12435.380064967916\n",
      "Testing Error 18260.852548799725\n",
      "--------------------\n",
      "---------- Alpha 0.033 ---------\n",
      "Training Error 12436.10974118691\n",
      "Testing Error 18260.45898969944\n",
      "--------------------\n",
      "---------- Alpha 0.034 ---------\n",
      "Training Error 12436.872469049023\n",
      "Testing Error 18260.06206355907\n",
      "--------------------\n",
      "---------- Alpha 0.035 ---------\n",
      "Training Error 12437.626915922034\n",
      "Testing Error 18259.66184345127\n",
      "--------------------\n",
      "---------- Alpha 0.036 ---------\n",
      "Training Error 12438.373241831194\n",
      "Testing Error 18259.25839958173\n",
      "--------------------\n",
      "---------- Alpha 0.037 ---------\n",
      "Training Error 12439.113849556423\n",
      "Testing Error 18258.851799507855\n",
      "--------------------\n",
      "---------- Alpha 0.038 ---------\n",
      "Training Error 12439.86758504629\n",
      "Testing Error 18258.442108336058\n",
      "--------------------\n",
      "---------- Alpha 0.039 ---------\n",
      "Training Error 12440.613548540205\n",
      "Testing Error 18258.029388898452\n",
      "--------------------\n",
      "---------- Alpha 0.04 ---------\n",
      "Training Error 12441.4001304412\n",
      "Testing Error 18257.61370190906\n",
      "--------------------\n",
      "---------- Alpha 0.041 ---------\n",
      "Training Error 12442.187326239971\n",
      "Testing Error 18257.195106109044\n",
      "--------------------\n",
      "---------- Alpha 0.042 ---------\n",
      "Training Error 12442.978595441018\n",
      "Testing Error 18256.77365839317\n",
      "--------------------\n",
      "---------- Alpha 0.043 ---------\n",
      "Training Error 12443.795249151877\n",
      "Testing Error 18256.396741352113\n",
      "--------------------\n",
      "---------- Alpha 0.044 ---------\n",
      "Training Error 12444.607608393671\n",
      "Testing Error 18256.057793139335\n",
      "--------------------\n",
      "---------- Alpha 0.045 ---------\n",
      "Training Error 12445.45446577835\n",
      "Testing Error 18255.715482122614\n",
      "--------------------\n",
      "---------- Alpha 0.046 ---------\n",
      "Training Error 12446.294029574066\n",
      "Testing Error 18255.36987180535\n",
      "--------------------\n",
      "---------- Alpha 0.047 ---------\n",
      "Training Error 12447.126172378063\n",
      "Testing Error 18255.021023867448\n",
      "--------------------\n",
      "---------- Alpha 0.048 ---------\n",
      "Training Error 12447.951005692696\n",
      "Testing Error 18254.668998261743\n",
      "--------------------\n",
      "---------- Alpha 0.049 ---------\n",
      "Training Error 12448.768637991398\n",
      "Testing Error 18254.31385330194\n",
      "--------------------\n",
      "---------- Alpha 0.05 ---------\n",
      "Training Error 12449.61138568047\n",
      "Testing Error 18254.124285433456\n",
      "--------------------\n",
      "---------- Alpha 0.051 ---------\n",
      "Training Error 12450.467139096678\n",
      "Testing Error 18253.96249796567\n",
      "--------------------\n",
      "---------- Alpha 0.052 ---------\n",
      "Training Error 12451.381593482094\n",
      "Testing Error 18253.796578674046\n",
      "--------------------\n",
      "---------- Alpha 0.053 ---------\n",
      "Training Error 12452.295045063307\n",
      "Testing Error 18253.626596903443\n",
      "--------------------\n",
      "---------- Alpha 0.054 ---------\n",
      "Training Error 12453.205444570413\n",
      "Testing Error 18253.452620161082\n",
      "--------------------\n",
      "---------- Alpha 0.055 ---------\n",
      "Training Error 12454.134035935867\n",
      "Testing Error 18253.27471420059\n",
      "--------------------\n",
      "---------- Alpha 0.056 ---------\n",
      "Training Error 12455.086637089513\n",
      "Testing Error 18253.092943103136\n",
      "--------------------\n",
      "---------- Alpha 0.057 ---------\n",
      "Training Error 12456.130844751071\n",
      "Testing Error 18252.907369351375\n",
      "--------------------\n",
      "---------- Alpha 0.058 ---------\n",
      "Training Error 12457.258140154847\n",
      "Testing Error 18252.71805389866\n",
      "--------------------\n",
      "---------- Alpha 0.059 ---------\n",
      "Training Error 12458.37635565217\n",
      "Testing Error 18252.525056234197\n",
      "--------------------\n",
      "---------- Alpha 0.06 ---------\n",
      "Training Error 12459.485605351065\n",
      "Testing Error 18252.32843444284\n",
      "--------------------\n",
      "---------- Alpha 0.061 ---------\n",
      "Training Error 12460.627028340923\n",
      "Testing Error 18252.12824526283\n",
      "--------------------\n",
      "---------- Alpha 0.062 ---------\n",
      "Training Error 12461.764219637476\n",
      "Testing Error 18251.924544138095\n",
      "--------------------\n",
      "---------- Alpha 0.063 ---------\n",
      "Training Error 12462.892498573821\n",
      "Testing Error 18251.717385268\n",
      "--------------------\n",
      "---------- Alpha 0.064 ---------\n",
      "Training Error 12464.011972986926\n",
      "Testing Error 18251.50682165496\n",
      "--------------------\n",
      "---------- Alpha 0.065 ---------\n",
      "Training Error 12465.137676118844\n",
      "Testing Error 18251.292905147813\n",
      "--------------------\n",
      "---------- Alpha 0.066 ---------\n",
      "Training Error 12466.274613326565\n",
      "Testing Error 18251.075686483742\n",
      "--------------------\n",
      "---------- Alpha 0.067 ---------\n",
      "Training Error 12467.584066338879\n",
      "Testing Error 18250.85521532764\n",
      "--------------------\n",
      "---------- Alpha 0.068 ---------\n",
      "Training Error 12469.058417755954\n",
      "Testing Error 18250.631540307826\n",
      "--------------------\n",
      "---------- Alpha 0.069 ---------\n",
      "Training Error 12470.52163399094\n",
      "Testing Error 18250.404709053117\n",
      "--------------------\n",
      "---------- Alpha 0.07 ---------\n",
      "Training Error 12471.973855054091\n",
      "Testing Error 18250.174768224377\n",
      "--------------------\n",
      "---------- Alpha 0.071 ---------\n",
      "Training Error 12473.415217847894\n",
      "Testing Error 18249.941763546696\n",
      "--------------------\n",
      "---------- Alpha 0.072 ---------\n",
      "Training Error 12474.845856279007\n",
      "Testing Error 18249.7057398386\n",
      "--------------------\n",
      "---------- Alpha 0.073 ---------\n",
      "Training Error 12476.265901364919\n",
      "Testing Error 18249.466741041284\n",
      "--------------------\n",
      "---------- Alpha 0.074 ---------\n",
      "Training Error 12477.675481335129\n",
      "Testing Error 18249.224810244024\n",
      "--------------------\n",
      "---------- Alpha 0.075 ---------\n",
      "Training Error 12479.086802002897\n",
      "Testing Error 18248.97998971152\n",
      "--------------------\n",
      "---------- Alpha 0.076 ---------\n",
      "Training Error 12480.60587692426\n",
      "Testing Error 18248.732320907107\n",
      "--------------------\n",
      "---------- Alpha 0.077 ---------\n",
      "Training Error 12482.190790631097\n",
      "Testing Error 18248.481844516253\n",
      "--------------------\n",
      "---------- Alpha 0.078 ---------\n",
      "Training Error 12483.76532824147\n",
      "Testing Error 18248.228600469138\n",
      "--------------------\n",
      "---------- Alpha 0.079 ---------\n",
      "Training Error 12485.357904269471\n",
      "Testing Error 18247.972627961568\n",
      "--------------------\n",
      "---------- Alpha 0.08 ---------\n",
      "Training Error 12486.98867108271\n",
      "Testing Error 18247.713965475392\n",
      "--------------------\n",
      "---------- Alpha 0.081 ---------\n",
      "Training Error 12488.636316535392\n",
      "Testing Error 18247.452650797375\n",
      "--------------------\n",
      "---------- Alpha 0.082 ---------\n",
      "Training Error 12490.272490226644\n",
      "Testing Error 18247.188721038958\n",
      "--------------------\n",
      "---------- Alpha 0.083 ---------\n",
      "Training Error 12491.907477037532\n",
      "Testing Error 18246.922212653124\n",
      "--------------------\n",
      "---------- Alpha 0.084 ---------\n",
      "Training Error 12493.534828734577\n",
      "Testing Error 18246.657331649432\n",
      "--------------------\n",
      "---------- Alpha 0.085 ---------\n",
      "Training Error 12495.151041677931\n",
      "Testing Error 18246.70801180952\n",
      "--------------------\n",
      "---------- Alpha 0.086 ---------\n",
      "Training Error 12496.756235375351\n",
      "Testing Error 18246.754679999223\n",
      "--------------------\n",
      "---------- Alpha 0.087 ---------\n",
      "Training Error 12498.351308001773\n",
      "Testing Error 18246.8503001616\n",
      "--------------------\n",
      "---------- Alpha 0.088 ---------\n",
      "Training Error 12499.952875221603\n",
      "Testing Error 18247.09228435152\n",
      "--------------------\n",
      "---------- Alpha 0.089 ---------\n",
      "Training Error 12501.600748633686\n",
      "Testing Error 18247.329140955906\n",
      "--------------------\n",
      "---------- Alpha 0.09 ---------\n",
      "Training Error 12503.278828425515\n",
      "Testing Error 18247.56092758979\n",
      "--------------------\n",
      "---------- Alpha 0.091 ---------\n",
      "Training Error 12504.945833437954\n",
      "Testing Error 18247.787700971385\n",
      "--------------------\n",
      "---------- Alpha 0.092 ---------\n",
      "Training Error 12506.601876310793\n",
      "Testing Error 18248.009516941525\n",
      "--------------------\n",
      "---------- Alpha 0.093 ---------\n",
      "Training Error 12508.247067878485\n",
      "Testing Error 18248.22643048355\n",
      "--------------------\n",
      "---------- Alpha 0.094 ---------\n",
      "Training Error 12509.881517214893\n",
      "Testing Error 18248.43849574169\n",
      "--------------------\n",
      "---------- Alpha 0.095 ---------\n",
      "Training Error 12511.505331676775\n",
      "Testing Error 18248.645766039448\n",
      "--------------------\n",
      "---------- Alpha 0.096 ---------\n",
      "Training Error 12513.1282385631\n",
      "Testing Error 18248.84829389678\n",
      "--------------------\n",
      "---------- Alpha 0.097 ---------\n",
      "Training Error 12514.764258280913\n",
      "Testing Error 18249.04613104774\n",
      "--------------------\n",
      "---------- Alpha 0.098 ---------\n",
      "Training Error 12516.3897934535\n",
      "Testing Error 18249.239328456188\n",
      "--------------------\n",
      "---------- Alpha 0.099 ---------\n",
      "Training Error 12518.0049461209\n",
      "Testing Error 18249.42793633254\n",
      "--------------------\n",
      "---------- Alpha 0.1 ---------\n",
      "Training Error 12519.60981679216\n",
      "Testing Error 18249.612004149123\n",
      "--------------------\n",
      "---------- Alpha 0.101 ---------\n",
      "Training Error 12521.208405888843\n",
      "Testing Error 18249.791580654804\n",
      "--------------------\n",
      "---------- Alpha 0.102 ---------\n",
      "Training Error 12522.801879063332\n",
      "Testing Error 18249.96671389028\n",
      "--------------------\n",
      "---------- Alpha 0.103 ---------\n",
      "Training Error 12524.391287923874\n",
      "Testing Error 18250.137451202\n",
      "--------------------\n",
      "---------- Alpha 0.104 ---------\n",
      "Training Error 12525.970800388845\n",
      "Testing Error 18250.30383925584\n",
      "--------------------\n",
      "---------- Alpha 0.105 ---------\n",
      "Training Error 12527.540509369737\n",
      "Testing Error 18250.46592405099\n",
      "--------------------\n",
      "---------- Alpha 0.106 ---------\n",
      "Training Error 12529.100506453957\n",
      "Testing Error 18250.623750932522\n",
      "--------------------\n",
      "---------- Alpha 0.107 ---------\n",
      "Training Error 12530.65088193311\n",
      "Testing Error 18250.77736460483\n",
      "--------------------\n",
      "---------- Alpha 0.108 ---------\n",
      "Training Error 12532.191724830387\n",
      "Testing Error 18250.92680914301\n",
      "--------------------\n",
      "---------- Alpha 0.109 ---------\n",
      "Training Error 12533.728661821271\n",
      "Testing Error 18251.07212800585\n",
      "--------------------\n",
      "---------- Alpha 0.11 ---------\n",
      "Training Error 12535.30329442041\n",
      "Testing Error 18251.213364047006\n",
      "--------------------\n",
      "---------- Alpha 0.111 ---------\n",
      "Training Error 12536.878262527842\n",
      "Testing Error 18251.350559526698\n",
      "--------------------\n",
      "---------- Alpha 0.112 ---------\n",
      "Training Error 12538.447395780528\n",
      "Testing Error 18251.483756122605\n",
      "--------------------\n",
      "---------- Alpha 0.113 ---------\n",
      "Training Error 12540.019976624731\n",
      "Testing Error 18251.612994940835\n",
      "--------------------\n",
      "---------- Alpha 0.114 ---------\n",
      "Training Error 12541.613546119748\n",
      "Testing Error 18251.738316526702\n",
      "--------------------\n",
      "---------- Alpha 0.115 ---------\n",
      "Training Error 12543.197483554246\n",
      "Testing Error 18251.85976087456\n",
      "--------------------\n",
      "---------- Alpha 0.116 ---------\n",
      "Training Error 12544.771875796238\n",
      "Testing Error 18251.977367438285\n",
      "--------------------\n",
      "---------- Alpha 0.117 ---------\n",
      "Training Error 12546.336808547632\n",
      "Testing Error 18252.153346099898\n",
      "--------------------\n",
      "---------- Alpha 0.118 ---------\n",
      "Training Error 12547.90480625261\n",
      "Testing Error 18252.330838936832\n",
      "--------------------\n",
      "---------- Alpha 0.119 ---------\n",
      "Training Error 12549.468573249289\n",
      "Testing Error 18252.504256079737\n",
      "--------------------\n",
      "---------- Alpha 0.12 ---------\n",
      "Training Error 12551.023068249484\n",
      "Testing Error 18252.673637602387\n",
      "--------------------\n",
      "---------- Alpha 0.121 ---------\n",
      "Training Error 12552.568372881158\n",
      "Testing Error 18252.839023055407\n",
      "--------------------\n",
      "---------- Alpha 0.122 ---------\n",
      "Training Error 12554.135562793655\n",
      "Testing Error 18253.117466631593\n",
      "--------------------\n",
      "---------- Alpha 0.123 ---------\n",
      "Training Error 12555.759926335162\n",
      "Testing Error 18253.465310606545\n",
      "--------------------\n",
      "---------- Alpha 0.124 ---------\n",
      "Training Error 12557.417711752758\n",
      "Testing Error 18253.808418351524\n",
      "--------------------\n",
      "---------- Alpha 0.125 ---------\n",
      "Training Error 12559.071616693045\n",
      "Testing Error 18254.14683293444\n",
      "--------------------\n",
      "---------- Alpha 0.126 ---------\n",
      "Training Error 12560.71605764986\n",
      "Testing Error 18254.480596903362\n",
      "--------------------\n",
      "---------- Alpha 0.127 ---------\n",
      "Training Error 12562.35942454748\n",
      "Testing Error 18254.809752294877\n",
      "--------------------\n",
      "---------- Alpha 0.128 ---------\n",
      "Training Error 12564.043704653597\n",
      "Testing Error 18255.134340642122\n",
      "--------------------\n",
      "---------- Alpha 0.129 ---------\n",
      "Training Error 12565.721958046537\n",
      "Testing Error 18255.45440298259\n",
      "--------------------\n",
      "---------- Alpha 0.13 ---------\n",
      "Training Error 12567.423303095034\n",
      "Testing Error 18255.769979865803\n",
      "--------------------\n",
      "---------- Alpha 0.131 ---------\n",
      "Training Error 12569.115864425983\n",
      "Testing Error 18256.081111361178\n",
      "--------------------\n",
      "---------- Alpha 0.132 ---------\n",
      "Training Error 12570.799009716906\n",
      "Testing Error 18256.387837065366\n",
      "--------------------\n",
      "---------- Alpha 0.133 ---------\n",
      "Training Error 12572.47281698369\n",
      "Testing Error 18256.702550544378\n",
      "--------------------\n",
      "---------- Alpha 0.134 ---------\n",
      "Training Error 12574.13736330512\n",
      "Testing Error 18257.079569512494\n",
      "--------------------\n",
      "---------- Alpha 0.135 ---------\n",
      "Training Error 12575.800560498064\n",
      "Testing Error 18257.45190096289\n",
      "--------------------\n",
      "---------- Alpha 0.136 ---------\n",
      "Training Error 12577.45782328041\n",
      "Testing Error 18257.819585948157\n",
      "--------------------\n",
      "---------- Alpha 0.137 ---------\n",
      "Training Error 12579.159737591897\n",
      "Testing Error 18258.182665045908\n",
      "--------------------\n",
      "---------- Alpha 0.138 ---------\n",
      "Training Error 12580.858259152155\n",
      "Testing Error 18258.54117836645\n",
      "--------------------\n",
      "---------- Alpha 0.139 ---------\n",
      "Training Error 12582.547630800267\n",
      "Testing Error 18258.895165559123\n",
      "--------------------\n",
      "---------- Alpha 0.14 ---------\n",
      "Training Error 12584.227926026111\n",
      "Testing Error 18259.24466581982\n",
      "--------------------\n",
      "---------- Alpha 0.141 ---------\n",
      "Training Error 12585.899217468985\n",
      "Testing Error 18259.589717897263\n",
      "--------------------\n",
      "---------- Alpha 0.142 ---------\n",
      "Training Error 12587.561576931295\n",
      "Testing Error 18259.93036009979\n",
      "--------------------\n",
      "---------- Alpha 0.143 ---------\n",
      "Training Error 12589.21507539192\n",
      "Testing Error 18260.26663030174\n",
      "--------------------\n",
      "---------- Alpha 0.144 ---------\n",
      "Training Error 12590.85978301945\n",
      "Testing Error 18260.617242533597\n",
      "--------------------\n",
      "---------- Alpha 0.145 ---------\n",
      "Training Error 12592.49576918489\n",
      "Testing Error 18261.033560753654\n",
      "--------------------\n",
      "---------- Alpha 0.146 ---------\n",
      "Training Error 12594.123102474317\n",
      "Testing Error 18261.44517728972\n",
      "--------------------\n",
      "---------- Alpha 0.147 ---------\n",
      "Training Error 12595.74185070114\n",
      "Testing Error 18261.852132046122\n",
      "--------------------\n",
      "---------- Alpha 0.148 ---------\n",
      "Training Error 12597.3520809181\n",
      "Testing Error 18262.254464473288\n",
      "--------------------\n",
      "---------- Alpha 0.149 ---------\n",
      "Training Error 12598.95385942905\n",
      "Testing Error 18262.65221357521\n",
      "--------------------\n",
      "---------- Alpha 0.15 ---------\n",
      "Training Error 12600.54725180055\n",
      "Testing Error 18263.30002469633\n",
      "--------------------\n",
      "---------- Alpha 0.151 ---------\n",
      "Training Error 12602.132322872993\n",
      "Testing Error 18264.119318387104\n",
      "--------------------\n",
      "---------- Alpha 0.152 ---------\n",
      "Training Error 12603.717990672318\n",
      "Testing Error 18264.93242832592\n",
      "--------------------\n",
      "---------- Alpha 0.153 ---------\n",
      "Training Error 12605.313469834138\n",
      "Testing Error 18265.739402665247\n",
      "--------------------\n",
      "---------- Alpha 0.154 ---------\n",
      "Training Error 12606.916621215045\n",
      "Testing Error 18266.54028904592\n",
      "--------------------\n",
      "---------- Alpha 0.155 ---------\n",
      "Training Error 12608.519272580294\n",
      "Testing Error 18267.335134604513\n",
      "--------------------\n",
      "---------- Alpha 0.156 ---------\n",
      "Training Error 12610.114832943746\n",
      "Testing Error 18268.123985980314\n",
      "--------------------\n",
      "---------- Alpha 0.157 ---------\n",
      "Training Error 12611.721275681326\n",
      "Testing Error 18268.90688932208\n",
      "--------------------\n",
      "---------- Alpha 0.158 ---------\n",
      "Training Error 12613.340357688068\n",
      "Testing Error 18269.70850341985\n",
      "--------------------\n",
      "---------- Alpha 0.159 ---------\n",
      "Training Error 12614.958117593533\n",
      "Testing Error 18270.52750035519\n",
      "--------------------\n",
      "---------- Alpha 0.16 ---------\n",
      "Training Error 12616.567726781417\n",
      "Testing Error 18271.363524530294\n",
      "--------------------\n",
      "---------- Alpha 0.161 ---------\n",
      "Training Error 12618.183031766099\n",
      "Testing Error 18272.22127775296\n",
      "--------------------\n",
      "---------- Alpha 0.162 ---------\n",
      "Training Error 12619.802245618437\n",
      "Testing Error 18273.073030147378\n",
      "--------------------\n",
      "---------- Alpha 0.163 ---------\n",
      "Training Error 12621.413386349812\n",
      "Testing Error 18273.91882635917\n",
      "--------------------\n",
      "---------- Alpha 0.164 ---------\n",
      "Training Error 12623.016513349849\n",
      "Testing Error 18274.758710580692\n",
      "--------------------\n",
      "---------- Alpha 0.165 ---------\n",
      "Training Error 12624.611685391215\n",
      "Testing Error 18275.592726556653\n",
      "--------------------\n",
      "---------- Alpha 0.166 ---------\n",
      "Training Error 12626.198960638225\n",
      "Testing Error 18276.420917589934\n",
      "--------------------\n",
      "---------- Alpha 0.167 ---------\n",
      "Training Error 12627.778396655314\n",
      "Testing Error 18277.243326547956\n",
      "--------------------\n",
      "---------- Alpha 0.168 ---------\n",
      "Training Error 12629.350050415516\n",
      "Testing Error 18278.05999586777\n",
      "--------------------\n",
      "---------- Alpha 0.169 ---------\n",
      "Training Error 12630.913978308427\n",
      "Testing Error 18278.870967562598\n",
      "--------------------\n",
      "---------- Alpha 0.17 ---------\n",
      "Training Error 12632.47023614854\n",
      "Testing Error 18279.67628322664\n",
      "--------------------\n",
      "---------- Alpha 0.171 ---------\n",
      "Training Error 12634.018879182837\n",
      "Testing Error 18280.475984040724\n",
      "--------------------\n",
      "---------- Alpha 0.172 ---------\n",
      "Training Error 12635.56471533696\n",
      "Testing Error 18281.336806170762\n",
      "--------------------\n",
      "---------- Alpha 0.173 ---------\n",
      "Training Error 12637.1157323896\n",
      "Testing Error 18282.265166943325\n",
      "--------------------\n",
      "---------- Alpha 0.174 ---------\n",
      "Training Error 12638.65923567742\n",
      "Testing Error 18283.18744707167\n",
      "--------------------\n",
      "---------- Alpha 0.175 ---------\n",
      "Training Error 12640.195278637648\n",
      "Testing Error 18284.256003933657\n",
      "--------------------\n",
      "---------- Alpha 0.176 ---------\n",
      "Training Error 12641.723914174125\n",
      "Testing Error 18285.35056648723\n",
      "--------------------\n",
      "---------- Alpha 0.177 ---------\n",
      "Training Error 12643.245194664465\n",
      "Testing Error 18286.43849688504\n",
      "--------------------\n",
      "---------- Alpha 0.178 ---------\n",
      "Training Error 12644.759171967107\n",
      "Testing Error 18287.519840923967\n",
      "--------------------\n",
      "---------- Alpha 0.179 ---------\n",
      "Training Error 12646.265897428058\n",
      "Testing Error 18288.594643968365\n",
      "--------------------\n",
      "---------- Alpha 0.18 ---------\n",
      "Training Error 12647.765421887847\n",
      "Testing Error 18289.66295095529\n",
      "--------------------\n",
      "---------- Alpha 0.181 ---------\n",
      "Training Error 12649.257795687992\n",
      "Testing Error 18290.724806399805\n",
      "--------------------\n",
      "---------- Alpha 0.182 ---------\n",
      "Training Error 12650.743068677632\n",
      "Testing Error 18291.780254400343\n",
      "--------------------\n",
      "---------- Alpha 0.183 ---------\n",
      "Training Error 12652.221290219955\n",
      "Testing Error 18292.82933864355\n",
      "--------------------\n",
      "---------- Alpha 0.184 ---------\n",
      "Training Error 12653.742023406758\n",
      "Testing Error 18293.872102409663\n",
      "--------------------\n",
      "---------- Alpha 0.185 ---------\n",
      "Training Error 12655.303509535428\n",
      "Testing Error 18294.908588577153\n",
      "--------------------\n",
      "---------- Alpha 0.186 ---------\n",
      "Training Error 12656.857611187395\n",
      "Testing Error 18295.98451132519\n",
      "--------------------\n",
      "---------- Alpha 0.187 ---------\n",
      "Training Error 12658.411083985813\n",
      "Testing Error 18297.071450280007\n",
      "--------------------\n",
      "---------- Alpha 0.188 ---------\n",
      "Training Error 12659.978476519052\n",
      "Testing Error 18298.152017902532\n",
      "--------------------\n",
      "---------- Alpha 0.189 ---------\n",
      "Training Error 12661.53853051401\n",
      "Testing Error 18299.226256831997\n",
      "--------------------\n",
      "---------- Alpha 0.19 ---------\n",
      "Training Error 12663.091296206685\n",
      "Testing Error 18300.294209318326\n",
      "--------------------\n",
      "---------- Alpha 0.191 ---------\n",
      "Training Error 12664.63682335544\n",
      "Testing Error 18301.355917226265\n",
      "--------------------\n",
      "---------- Alpha 0.192 ---------\n",
      "Training Error 12666.183897786923\n",
      "Testing Error 18302.411422040288\n",
      "--------------------\n",
      "---------- Alpha 0.193 ---------\n",
      "Training Error 12667.734103328869\n",
      "Testing Error 18303.46076486887\n",
      "--------------------\n",
      "---------- Alpha 0.194 ---------\n",
      "Training Error 12669.287921829076\n",
      "Testing Error 18304.503986449115\n",
      "--------------------\n",
      "---------- Alpha 0.195 ---------\n",
      "Training Error 12670.83463556108\n",
      "Testing Error 18305.541127151202\n",
      "--------------------\n",
      "---------- Alpha 0.196 ---------\n",
      "Training Error 12672.374292220433\n",
      "Testing Error 18306.572226982633\n",
      "--------------------\n",
      "---------- Alpha 0.197 ---------\n",
      "Training Error 12673.906939057662\n",
      "Testing Error 18307.597325592338\n",
      "--------------------\n",
      "---------- Alpha 0.198 ---------\n",
      "Training Error 12675.432622883918\n",
      "Testing Error 18308.61646227526\n",
      "--------------------\n",
      "---------- Alpha 0.199 ---------\n",
      "Training Error 12676.951390076229\n",
      "Testing Error 18309.629675976117\n",
      "--------------------\n",
      "---------- Alpha 0.2 ---------\n",
      "Training Error 12678.510939270021\n",
      "Testing Error 18310.637005293745\n",
      "--------------------\n",
      "---------- Alpha 0.201 ---------\n",
      "Training Error 12680.07107810678\n",
      "Testing Error 18311.63848848497\n",
      "--------------------\n",
      "---------- Alpha 0.202 ---------\n",
      "Training Error 12681.624246828658\n",
      "Testing Error 18312.77584111184\n",
      "--------------------\n",
      "---------- Alpha 0.203 ---------\n",
      "Training Error 12683.170491183231\n",
      "Testing Error 18313.93542518843\n",
      "--------------------\n",
      "---------- Alpha 0.204 ---------\n",
      "Training Error 12684.709856501342\n",
      "Testing Error 18315.088839041637\n",
      "--------------------\n",
      "---------- Alpha 0.205 ---------\n",
      "Training Error 12686.242387702\n",
      "Testing Error 18316.2361205552\n",
      "--------------------\n",
      "---------- Alpha 0.206 ---------\n",
      "Training Error 12687.786438093977\n",
      "Testing Error 18317.377307304265\n",
      "--------------------\n",
      "---------- Alpha 0.207 ---------\n",
      "Training Error 12689.324934544724\n",
      "Testing Error 18318.512436557663\n",
      "--------------------\n",
      "---------- Alpha 0.208 ---------\n",
      "Training Error 12690.866853813026\n",
      "Testing Error 18319.641545281847\n",
      "--------------------\n",
      "---------- Alpha 0.209 ---------\n",
      "Training Error 12692.405593267189\n",
      "Testing Error 18320.764670143675\n",
      "--------------------\n",
      "---------- Alpha 0.21 ---------\n",
      "Training Error 12693.937616663252\n",
      "Testing Error 18321.881847513574\n",
      "--------------------\n",
      "---------- Alpha 0.211 ---------\n",
      "Training Error 12695.462967061476\n",
      "Testing Error 18322.993113468674\n",
      "--------------------\n",
      "---------- Alpha 0.212 ---------\n",
      "Training Error 12696.981687139647\n",
      "Testing Error 18324.098503795547\n",
      "--------------------\n",
      "---------- Alpha 0.213 ---------\n",
      "Training Error 12698.493819197609\n",
      "Testing Error 18325.198053993514\n",
      "--------------------\n",
      "---------- Alpha 0.214 ---------\n",
      "Training Error 12699.999405161652\n",
      "Testing Error 18326.291799277325\n",
      "--------------------\n",
      "---------- Alpha 0.215 ---------\n",
      "Training Error 12701.504166805493\n",
      "Testing Error 18327.379774580208\n",
      "--------------------\n",
      "---------- Alpha 0.216 ---------\n",
      "Training Error 12703.0252648516\n",
      "Testing Error 18328.46201455654\n",
      "--------------------\n",
      "---------- Alpha 0.217 ---------\n",
      "Training Error 12704.563462998614\n",
      "Testing Error 18329.538553584942\n",
      "--------------------\n",
      "---------- Alpha 0.218 ---------\n",
      "Training Error 12706.095094982373\n",
      "Testing Error 18330.609425770817\n",
      "--------------------\n",
      "---------- Alpha 0.219 ---------\n",
      "Training Error 12707.620202007034\n",
      "Testing Error 18331.674664949307\n",
      "--------------------\n",
      "---------- Alpha 0.22 ---------\n",
      "Training Error 12709.138824919124\n",
      "Testing Error 18332.73430468773\n",
      "--------------------\n",
      "---------- Alpha 0.221 ---------\n",
      "Training Error 12710.65100421166\n",
      "Testing Error 18333.788378288726\n",
      "--------------------\n",
      "---------- Alpha 0.222 ---------\n",
      "Training Error 12712.16109649347\n",
      "Testing Error 18334.836918792265\n",
      "--------------------\n",
      "---------- Alpha 0.223 ---------\n",
      "Training Error 12713.680891196444\n",
      "Testing Error 18335.87995897895\n",
      "--------------------\n",
      "---------- Alpha 0.224 ---------\n",
      "Training Error 12715.194306098543\n",
      "Testing Error 18336.917531372048\n",
      "--------------------\n",
      "---------- Alpha 0.225 ---------\n",
      "Training Error 12716.701380596201\n",
      "Testing Error 18337.949668240537\n",
      "--------------------\n",
      "---------- Alpha 0.226 ---------\n",
      "Training Error 12718.202153749688\n",
      "Testing Error 18338.976401601027\n",
      "--------------------\n",
      "---------- Alpha 0.227 ---------\n",
      "Training Error 12719.703465751927\n",
      "Testing Error 18339.99776322087\n",
      "--------------------\n",
      "---------- Alpha 0.228 ---------\n",
      "Training Error 12721.21020501693\n",
      "Testing Error 18341.013784620292\n",
      "--------------------\n",
      "---------- Alpha 0.229 ---------\n",
      "Training Error 12722.776320558565\n",
      "Testing Error 18342.02449707481\n",
      "--------------------\n",
      "---------- Alpha 0.23 ---------\n",
      "Training Error 12724.348825048783\n",
      "Testing Error 18343.029931617893\n",
      "--------------------\n",
      "---------- Alpha 0.231 ---------\n",
      "Training Error 12725.970409700258\n",
      "Testing Error 18344.03011904286\n",
      "--------------------\n",
      "---------- Alpha 0.232 ---------\n",
      "Training Error 12727.588631255807\n",
      "Testing Error 18345.02508990578\n",
      "--------------------\n",
      "---------- Alpha 0.233 ---------\n",
      "Training Error 12729.200328563782\n",
      "Testing Error 18346.014874527336\n",
      "--------------------\n",
      "---------- Alpha 0.234 ---------\n",
      "Training Error 12730.819701251316\n",
      "Testing Error 18346.99950299556\n",
      "--------------------\n",
      "---------- Alpha 0.235 ---------\n",
      "Training Error 12732.436402888561\n",
      "Testing Error 18347.979005167617\n",
      "--------------------\n",
      "---------- Alpha 0.236 ---------\n",
      "Training Error 12734.046664631545\n",
      "Testing Error 18348.95341067232\n",
      "--------------------\n",
      "---------- Alpha 0.237 ---------\n",
      "Training Error 12735.65052457994\n",
      "Testing Error 18349.9227489124\n",
      "--------------------\n",
      "---------- Alpha 0.238 ---------\n",
      "Training Error 12737.248020521534\n",
      "Testing Error 18350.89400344773\n",
      "--------------------\n",
      "---------- Alpha 0.239 ---------\n",
      "Training Error 12738.839189935446\n",
      "Testing Error 18351.91620216815\n",
      "--------------------\n",
      "---------- Alpha 0.24 ---------\n",
      "Training Error 12740.424069995524\n",
      "Testing Error 18352.93325092218\n",
      "--------------------\n",
      "---------- Alpha 0.241 ---------\n",
      "Training Error 12742.002697573567\n",
      "Testing Error 18353.945179048216\n",
      "--------------------\n",
      "---------- Alpha 0.242 ---------\n",
      "Training Error 12743.575109242376\n",
      "Testing Error 18354.952015663217\n",
      "--------------------\n",
      "---------- Alpha 0.243 ---------\n",
      "Training Error 12745.166578092678\n",
      "Testing Error 18355.953789665044\n",
      "--------------------\n",
      "---------- Alpha 0.244 ---------\n",
      "Training Error 12746.77353271768\n",
      "Testing Error 18356.95052973408\n",
      "--------------------\n",
      "---------- Alpha 0.245 ---------\n",
      "Training Error 12748.377471565527\n",
      "Testing Error 18357.942264336045\n",
      "--------------------\n",
      "---------- Alpha 0.246 ---------\n",
      "Training Error 12749.992320066503\n",
      "Testing Error 18358.929021723245\n",
      "--------------------\n",
      "---------- Alpha 0.247 ---------\n",
      "Training Error 12751.611194851548\n",
      "Testing Error 18359.910829937126\n",
      "--------------------\n",
      "---------- Alpha 0.248 ---------\n",
      "Training Error 12753.234296719602\n",
      "Testing Error 18360.8877168101\n",
      "--------------------\n",
      "---------- Alpha 0.249 ---------\n",
      "Training Error 12754.851154070677\n",
      "Testing Error 18361.865867318626\n",
      "--------------------\n",
      "---------- Alpha 0.25 ---------\n",
      "Training Error 12756.466712285344\n",
      "Testing Error 18362.858262408008\n",
      "--------------------\n",
      "---------- Alpha 0.251 ---------\n",
      "Training Error 12758.084117515402\n",
      "Testing Error 18363.8968166957\n",
      "--------------------\n",
      "---------- Alpha 0.252 ---------\n",
      "Training Error 12759.715413791335\n",
      "Testing Error 18364.947302908207\n",
      "--------------------\n",
      "---------- Alpha 0.253 ---------\n",
      "Training Error 12761.347446466547\n",
      "Testing Error 18365.99271717618\n",
      "--------------------\n",
      "---------- Alpha 0.254 ---------\n",
      "Training Error 12762.985765761501\n",
      "Testing Error 18367.033087436852\n",
      "--------------------\n",
      "---------- Alpha 0.255 ---------\n",
      "Training Error 12764.617909271989\n",
      "Testing Error 18368.083680614516\n",
      "--------------------\n",
      "---------- Alpha 0.256 ---------\n",
      "Training Error 12766.243911681677\n",
      "Testing Error 18369.170465263654\n",
      "--------------------\n",
      "---------- Alpha 0.257 ---------\n",
      "Training Error 12767.874336387213\n",
      "Testing Error 18370.29695960283\n",
      "--------------------\n",
      "---------- Alpha 0.258 ---------\n",
      "Training Error 12769.527583688836\n",
      "Testing Error 18371.418191806617\n",
      "--------------------\n",
      "---------- Alpha 0.259 ---------\n",
      "Training Error 12771.17889263877\n",
      "Testing Error 18372.534190533086\n",
      "--------------------\n",
      "---------- Alpha 0.26 ---------\n",
      "Training Error 12772.824062329197\n",
      "Testing Error 18373.644984233582\n",
      "--------------------\n",
      "---------- Alpha 0.261 ---------\n",
      "Training Error 12774.463126791927\n",
      "Testing Error 18374.750601154657\n",
      "--------------------\n",
      "---------- Alpha 0.262 ---------\n",
      "Training Error 12776.09926879547\n",
      "Testing Error 18375.851069340042\n",
      "--------------------\n",
      "---------- Alpha 0.263 ---------\n",
      "Training Error 12777.735410347257\n",
      "Testing Error 18376.94641663191\n",
      "--------------------\n",
      "---------- Alpha 0.264 ---------\n",
      "Training Error 12779.365512731629\n",
      "Testing Error 18378.036670673344\n",
      "--------------------\n",
      "---------- Alpha 0.265 ---------\n",
      "Training Error 12780.989609115892\n",
      "Testing Error 18379.121858909864\n",
      "--------------------\n",
      "---------- Alpha 0.266 ---------\n",
      "Training Error 12782.623098977965\n",
      "Testing Error 18380.20200859119\n",
      "--------------------\n",
      "---------- Alpha 0.267 ---------\n",
      "Training Error 12784.261027728304\n",
      "Testing Error 18381.277146772944\n",
      "--------------------\n",
      "---------- Alpha 0.268 ---------\n",
      "Training Error 12785.892966961157\n",
      "Testing Error 18382.347300318554\n",
      "--------------------\n",
      "---------- Alpha 0.269 ---------\n",
      "Training Error 12787.518949268444\n",
      "Testing Error 18383.41249590096\n",
      "--------------------\n",
      "---------- Alpha 0.27 ---------\n",
      "Training Error 12789.139006997455\n",
      "Testing Error 18384.47276000418\n",
      "--------------------\n",
      "---------- Alpha 0.271 ---------\n",
      "Training Error 12790.773626306149\n",
      "Testing Error 18385.52811892496\n",
      "--------------------\n",
      "---------- Alpha 0.272 ---------\n",
      "Training Error 12792.414487297034\n",
      "Testing Error 18386.5785987747\n",
      "--------------------\n",
      "---------- Alpha 0.273 ---------\n",
      "Training Error 12794.06894842881\n",
      "Testing Error 18387.624225480908\n",
      "--------------------\n",
      "---------- Alpha 0.274 ---------\n",
      "Training Error 12795.741305875503\n",
      "Testing Error 18388.665024788752\n",
      "--------------------\n",
      "---------- Alpha 0.275 ---------\n",
      "Training Error 12797.413753943678\n",
      "Testing Error 18389.701022262914\n",
      "--------------------\n",
      "---------- Alpha 0.276 ---------\n",
      "Training Error 12799.080285785829\n",
      "Testing Error 18390.73224328902\n",
      "--------------------\n",
      "---------- Alpha 0.277 ---------\n",
      "Training Error 12800.740932634002\n",
      "Testing Error 18391.758713075233\n",
      "--------------------\n",
      "---------- Alpha 0.278 ---------\n",
      "Training Error 12802.395725492752\n",
      "Testing Error 18392.78045665382\n",
      "--------------------\n",
      "---------- Alpha 0.279 ---------\n",
      "Training Error 12804.04469514112\n",
      "Testing Error 18393.797498882814\n",
      "--------------------\n",
      "---------- Alpha 0.28 ---------\n",
      "Training Error 12805.687872134837\n",
      "Testing Error 18394.80986444725\n",
      "--------------------\n",
      "---------- Alpha 0.281 ---------\n",
      "Training Error 12807.325286808411\n",
      "Testing Error 18395.817577861028\n",
      "--------------------\n",
      "---------- Alpha 0.282 ---------\n",
      "Training Error 12808.95696927719\n",
      "Testing Error 18396.820663468152\n",
      "--------------------\n",
      "---------- Alpha 0.283 ---------\n",
      "Training Error 12810.58294943942\n",
      "Testing Error 18397.819145444355\n",
      "--------------------\n",
      "---------- Alpha 0.284 ---------\n",
      "Training Error 12812.20325697815\n",
      "Testing Error 18398.813047798496\n",
      "--------------------\n",
      "---------- Alpha 0.285 ---------\n",
      "Training Error 12813.827474852114\n",
      "Testing Error 18399.802394373997\n",
      "--------------------\n",
      "---------- Alpha 0.286 ---------\n",
      "Training Error 12815.4529622998\n",
      "Testing Error 18400.78720885036\n",
      "--------------------\n",
      "---------- Alpha 0.287 ---------\n",
      "Training Error 12817.072814477277\n",
      "Testing Error 18401.76751474441\n",
      "--------------------\n",
      "---------- Alpha 0.288 ---------\n",
      "Training Error 12818.709891951457\n",
      "Testing Error 18402.743335411924\n",
      "--------------------\n",
      "---------- Alpha 0.289 ---------\n",
      "Training Error 12820.346668772108\n",
      "Testing Error 18403.714694048955\n",
      "--------------------\n",
      "---------- Alpha 0.29 ---------\n",
      "Training Error 12821.977802748186\n",
      "Testing Error 18404.68161369303\n",
      "--------------------\n",
      "---------- Alpha 0.291 ---------\n",
      "Training Error 12823.603322836872\n",
      "Testing Error 18405.644117224754\n",
      "--------------------\n",
      "---------- Alpha 0.292 ---------\n",
      "Training Error 12825.223257790492\n",
      "Testing Error 18406.602227368974\n",
      "--------------------\n",
      "---------- Alpha 0.293 ---------\n",
      "Training Error 12826.837636158365\n",
      "Testing Error 18407.555966696218\n",
      "--------------------\n",
      "---------- Alpha 0.294 ---------\n",
      "Training Error 12828.446486288725\n",
      "Testing Error 18408.509243099274\n",
      "--------------------\n",
      "---------- Alpha 0.295 ---------\n",
      "Training Error 12830.049836330501\n",
      "Testing Error 18409.536102530532\n",
      "--------------------\n",
      "---------- Alpha 0.296 ---------\n",
      "Training Error 12831.648595998458\n",
      "Testing Error 18410.574655598673\n",
      "--------------------\n",
      "---------- Alpha 0.297 ---------\n",
      "Training Error 12833.246446514764\n",
      "Testing Error 18411.608679283352\n",
      "--------------------\n",
      "---------- Alpha 0.298 ---------\n",
      "Training Error 12834.838847043997\n",
      "Testing Error 18412.638196385597\n",
      "--------------------\n",
      "---------- Alpha 0.299 ---------\n",
      "Training Error 12836.425825145958\n",
      "Testing Error 18413.71588272178\n",
      "--------------------\n",
      "---------- Alpha 0.3 ---------\n",
      "Training Error 12838.015017681795\n",
      "Testing Error 18414.81818371475\n",
      "--------------------\n",
      "---------- Alpha 0.301 ---------\n",
      "Training Error 12839.61620574817\n",
      "Testing Error 18415.91581939911\n",
      "--------------------\n",
      "---------- Alpha 0.302 ---------\n",
      "Training Error 12841.211982880139\n",
      "Testing Error 18417.008812991444\n",
      "--------------------\n",
      "---------- Alpha 0.303 ---------\n",
      "Training Error 12842.802376190255\n",
      "Testing Error 18418.09718755502\n",
      "--------------------\n",
      "---------- Alpha 0.304 ---------\n",
      "Training Error 12844.387412604041\n",
      "Testing Error 18419.180966000524\n",
      "--------------------\n",
      "---------- Alpha 0.305 ---------\n",
      "Training Error 12845.967118861683\n",
      "Testing Error 18420.260171087484\n",
      "--------------------\n",
      "---------- Alpha 0.306 ---------\n",
      "Training Error 12847.541521519699\n",
      "Testing Error 18421.334825425798\n",
      "--------------------\n",
      "---------- Alpha 0.307 ---------\n",
      "Training Error 12849.119495777808\n",
      "Testing Error 18422.404951476452\n",
      "--------------------\n",
      "---------- Alpha 0.308 ---------\n",
      "Training Error 12850.692862293674\n",
      "Testing Error 18423.470571553207\n",
      "--------------------\n",
      "---------- Alpha 0.309 ---------\n",
      "Training Error 12852.261000611565\n",
      "Testing Error 18424.53170782369\n",
      "--------------------\n",
      "---------- Alpha 0.31 ---------\n",
      "Training Error 12853.842179063717\n",
      "Testing Error 18425.58838231053\n",
      "--------------------\n",
      "---------- Alpha 0.311 ---------\n",
      "Training Error 12855.418448608556\n",
      "Testing Error 18426.64061689252\n",
      "--------------------\n",
      "---------- Alpha 0.312 ---------\n",
      "Training Error 12856.989521663365\n",
      "Testing Error 18427.688433306077\n",
      "--------------------\n",
      "---------- Alpha 0.313 ---------\n",
      "Training Error 12858.570402681748\n",
      "Testing Error 18428.731853146048\n",
      "--------------------\n",
      "---------- Alpha 0.314 ---------\n",
      "Training Error 12860.148387593938\n",
      "Testing Error 18429.770897867023\n",
      "--------------------\n",
      "---------- Alpha 0.315 ---------\n",
      "Training Error 12861.721200751044\n",
      "Testing Error 18430.809237003603\n",
      "--------------------\n",
      "---------- Alpha 0.316 ---------\n",
      "Training Error 12863.288867372627\n",
      "Testing Error 18431.896215316716\n",
      "--------------------\n",
      "---------- Alpha 0.317 ---------\n",
      "Training Error 12864.851412509031\n",
      "Testing Error 18432.978715188354\n",
      "--------------------\n",
      "---------- Alpha 0.318 ---------\n",
      "Training Error 12866.408861042766\n",
      "Testing Error 18434.056758274695\n",
      "--------------------\n",
      "---------- Alpha 0.319 ---------\n",
      "Training Error 12867.961237689899\n",
      "Testing Error 18435.130366092642\n",
      "--------------------\n",
      "---------- Alpha 0.32 ---------\n",
      "Training Error 12869.508567001552\n",
      "Testing Error 18436.226570183175\n",
      "--------------------\n",
      "---------- Alpha 0.321 ---------\n",
      "Training Error 12871.050873365293\n",
      "Testing Error 18437.3984081912\n",
      "--------------------\n",
      "---------- Alpha 0.322 ---------\n",
      "Training Error 12872.602171595225\n",
      "Testing Error 18438.565700799685\n",
      "--------------------\n",
      "---------- Alpha 0.323 ---------\n",
      "Training Error 12874.160535314872\n",
      "Testing Error 18439.728469344125\n",
      "--------------------\n",
      "---------- Alpha 0.324 ---------\n",
      "Training Error 12875.71389625333\n",
      "Testing Error 18440.88673502456\n",
      "--------------------\n",
      "---------- Alpha 0.325 ---------\n",
      "Training Error 12877.262278352378\n",
      "Testing Error 18442.04051890741\n",
      "--------------------\n",
      "---------- Alpha 0.326 ---------\n",
      "Training Error 12878.805705395947\n",
      "Testing Error 18443.189841925792\n",
      "--------------------\n",
      "---------- Alpha 0.327 ---------\n",
      "Training Error 12880.347960910465\n",
      "Testing Error 18444.33472488108\n",
      "--------------------\n",
      "---------- Alpha 0.328 ---------\n",
      "Training Error 12881.89753492942\n",
      "Testing Error 18445.475188443736\n",
      "--------------------\n",
      "---------- Alpha 0.329 ---------\n",
      "Training Error 12883.442196836108\n",
      "Testing Error 18446.670374528338\n",
      "--------------------\n",
      "---------- Alpha 0.33 ---------\n",
      "Training Error 12884.981969885073\n",
      "Testing Error 18447.87064274833\n",
      "--------------------\n",
      "---------- Alpha 0.331 ---------\n",
      "Training Error 12886.516877179276\n",
      "Testing Error 18449.06638387253\n",
      "--------------------\n",
      "---------- Alpha 0.332 ---------\n",
      "Training Error 12888.046941671277\n",
      "Testing Error 18450.257618835767\n",
      "--------------------\n",
      "---------- Alpha 0.333 ---------\n",
      "Training Error 12889.57218616461\n",
      "Testing Error 18451.44436844197\n",
      "--------------------\n",
      "---------- Alpha 0.334 ---------\n",
      "Training Error 12891.092633314887\n",
      "Testing Error 18452.626653365038\n",
      "--------------------\n",
      "---------- Alpha 0.335 ---------\n",
      "Training Error 12892.608305631198\n",
      "Testing Error 18453.804494150227\n",
      "--------------------\n",
      "---------- Alpha 0.336 ---------\n",
      "Training Error 12894.119225477121\n",
      "Testing Error 18454.977911214726\n",
      "--------------------\n",
      "---------- Alpha 0.337 ---------\n",
      "Training Error 12895.625415072116\n",
      "Testing Error 18456.14692484909\n",
      "--------------------\n",
      "---------- Alpha 0.338 ---------\n",
      "Training Error 12897.126896492575\n",
      "Testing Error 18457.31155521797\n",
      "--------------------\n",
      "---------- Alpha 0.339 ---------\n",
      "Training Error 12898.623691673125\n",
      "Testing Error 18458.471822361254\n",
      "--------------------\n",
      "---------- Alpha 0.34 ---------\n",
      "Training Error 12900.115822407715\n",
      "Testing Error 18459.62774619504\n",
      "--------------------\n",
      "---------- Alpha 0.341 ---------\n",
      "Training Error 12901.603310350778\n",
      "Testing Error 18460.779346512387\n",
      "--------------------\n",
      "---------- Alpha 0.342 ---------\n",
      "Training Error 12903.090787767924\n",
      "Testing Error 18461.926642984585\n",
      "--------------------\n",
      "---------- Alpha 0.343 ---------\n",
      "Training Error 12904.576559313891\n",
      "Testing Error 18463.06965516201\n",
      "--------------------\n",
      "---------- Alpha 0.344 ---------\n",
      "Training Error 12906.05773394894\n",
      "Testing Error 18464.208402474942\n",
      "--------------------\n",
      "---------- Alpha 0.345 ---------\n",
      "Training Error 12907.534332862675\n",
      "Testing Error 18465.342904234614\n",
      "--------------------\n",
      "---------- Alpha 0.346 ---------\n",
      "Training Error 12909.00637711034\n",
      "Testing Error 18466.473179634213\n",
      "--------------------\n",
      "---------- Alpha 0.347 ---------\n",
      "Training Error 12910.473887613849\n",
      "Testing Error 18467.599247749607\n",
      "--------------------\n",
      "---------- Alpha 0.348 ---------\n",
      "Training Error 12911.936885162908\n",
      "Testing Error 18468.721127540506\n",
      "--------------------\n",
      "---------- Alpha 0.349 ---------\n",
      "Training Error 12913.395390416023\n",
      "Testing Error 18469.838837850853\n",
      "--------------------\n",
      "---------- Alpha 0.35 ---------\n",
      "Training Error 12914.871696266697\n",
      "Testing Error 18470.95239741062\n",
      "--------------------\n",
      "---------- Alpha 0.351 ---------\n",
      "Training Error 12916.353556703\n",
      "Testing Error 18472.061824835702\n",
      "--------------------\n",
      "---------- Alpha 0.352 ---------\n",
      "Training Error 12917.830900003164\n",
      "Testing Error 18473.167138629517\n",
      "--------------------\n",
      "---------- Alpha 0.353 ---------\n",
      "Training Error 12919.313893991322\n",
      "Testing Error 18474.26835718351\n",
      "--------------------\n",
      "---------- Alpha 0.354 ---------\n",
      "Training Error 12920.794783749398\n",
      "Testing Error 18475.365498778086\n",
      "--------------------\n",
      "---------- Alpha 0.355 ---------\n",
      "Training Error 12922.271185603362\n",
      "Testing Error 18476.458581583433\n",
      "--------------------\n",
      "---------- Alpha 0.356 ---------\n",
      "Training Error 12923.743119818966\n",
      "Testing Error 18477.547623660623\n",
      "--------------------\n",
      "---------- Alpha 0.357 ---------\n",
      "Training Error 12925.21060653593\n",
      "Testing Error 18478.632642962024\n",
      "--------------------\n",
      "---------- Alpha 0.358 ---------\n",
      "Training Error 12926.673665769236\n",
      "Testing Error 18479.713657332373\n",
      "--------------------\n",
      "---------- Alpha 0.359 ---------\n",
      "Training Error 12928.132317409949\n",
      "Testing Error 18480.7906845097\n",
      "--------------------\n",
      "---------- Alpha 0.36 ---------\n",
      "Training Error 12929.586581226291\n",
      "Testing Error 18481.863742125955\n",
      "--------------------\n",
      "---------- Alpha 0.361 ---------\n",
      "Training Error 12931.036476864589\n",
      "Testing Error 18482.932847707827\n",
      "--------------------\n",
      "---------- Alpha 0.362 ---------\n",
      "Training Error 12932.482023850192\n",
      "Testing Error 18483.998018677652\n",
      "--------------------\n",
      "---------- Alpha 0.363 ---------\n",
      "Training Error 12933.9232415885\n",
      "Testing Error 18485.059272353992\n",
      "--------------------\n",
      "---------- Alpha 0.364 ---------\n",
      "Training Error 12935.360149365855\n",
      "Testing Error 18486.116625952727\n",
      "--------------------\n",
      "---------- Alpha 0.365 ---------\n",
      "Training Error 12936.792766350505\n",
      "Testing Error 18487.17009658771\n",
      "--------------------\n",
      "---------- Alpha 0.366 ---------\n",
      "Training Error 12938.221111593515\n",
      "Testing Error 18488.219701271286\n",
      "--------------------\n",
      "---------- Alpha 0.367 ---------\n",
      "Training Error 12939.645267328116\n",
      "Testing Error 18489.26545691538\n",
      "--------------------\n",
      "---------- Alpha 0.368 ---------\n",
      "Training Error 12941.073296693177\n",
      "Testing Error 18490.30738033228\n",
      "--------------------\n",
      "---------- Alpha 0.369 ---------\n",
      "Training Error 12942.503064037346\n",
      "Testing Error 18491.345488234903\n",
      "--------------------\n",
      "---------- Alpha 0.37 ---------\n",
      "Training Error 12943.93368410731\n",
      "Testing Error 18492.37979723821\n",
      "--------------------\n",
      "---------- Alpha 0.371 ---------\n",
      "Training Error 12945.360089916076\n",
      "Testing Error 18493.41032385937\n",
      "--------------------\n",
      "---------- Alpha 0.372 ---------\n",
      "Training Error 12946.782299970504\n",
      "Testing Error 18494.43708451894\n",
      "--------------------\n",
      "---------- Alpha 0.373 ---------\n",
      "Training Error 12948.200332665712\n",
      "Testing Error 18495.460095541148\n",
      "--------------------\n",
      "---------- Alpha 0.374 ---------\n",
      "Training Error 12949.614206285936\n",
      "Testing Error 18496.47937315507\n",
      "--------------------\n",
      "---------- Alpha 0.375 ---------\n",
      "Training Error 12951.023939005387\n",
      "Testing Error 18497.49493349484\n",
      "--------------------\n",
      "---------- Alpha 0.376 ---------\n",
      "Training Error 12952.429548889166\n",
      "Testing Error 18498.506792600827\n",
      "--------------------\n",
      "---------- Alpha 0.377 ---------\n",
      "Training Error 12953.831053894002\n",
      "Testing Error 18499.514966419953\n",
      "--------------------\n",
      "---------- Alpha 0.378 ---------\n",
      "Training Error 12955.228471869166\n",
      "Testing Error 18500.5194708067\n",
      "--------------------\n",
      "---------- Alpha 0.379 ---------\n",
      "Training Error 12956.624327069314\n",
      "Testing Error 18501.52032152351\n",
      "--------------------\n",
      "---------- Alpha 0.38 ---------\n",
      "Training Error 12958.022626540545\n",
      "Testing Error 18502.517534241728\n",
      "--------------------\n",
      "---------- Alpha 0.381 ---------\n",
      "Training Error 12959.416884652745\n",
      "Testing Error 18503.51112454194\n",
      "--------------------\n",
      "---------- Alpha 0.382 ---------\n",
      "Training Error 12960.807118773753\n",
      "Testing Error 18504.50110791515\n",
      "--------------------\n",
      "---------- Alpha 0.383 ---------\n",
      "Training Error 12962.193346168799\n",
      "Testing Error 18505.4874997627\n",
      "--------------------\n",
      "---------- Alpha 0.384 ---------\n",
      "Training Error 12963.575584001317\n",
      "Testing Error 18506.470315397735\n",
      "--------------------\n",
      "---------- Alpha 0.385 ---------\n",
      "Training Error 12964.953849333708\n",
      "Testing Error 18507.449570045243\n",
      "--------------------\n",
      "---------- Alpha 0.386 ---------\n",
      "Training Error 12966.32815912809\n",
      "Testing Error 18508.42527884299\n",
      "--------------------\n",
      "---------- Alpha 0.387 ---------\n",
      "Training Error 12967.69853024704\n",
      "Testing Error 18509.397456842187\n",
      "--------------------\n",
      "---------- Alpha 0.388 ---------\n",
      "Training Error 12969.06497945436\n",
      "Testing Error 18510.366119007685\n",
      "--------------------\n",
      "---------- Alpha 0.389 ---------\n",
      "Training Error 12970.427523415836\n",
      "Testing Error 18511.331280219394\n",
      "--------------------\n",
      "---------- Alpha 0.39 ---------\n",
      "Training Error 12971.786178699895\n",
      "Testing Error 18512.29295527204\n",
      "--------------------\n",
      "---------- Alpha 0.391 ---------\n",
      "Training Error 12973.144205990111\n",
      "Testing Error 18513.251158876363\n",
      "--------------------\n",
      "---------- Alpha 0.392 ---------\n",
      "Training Error 12974.50417594377\n",
      "Testing Error 18514.205905659564\n",
      "--------------------\n",
      "---------- Alpha 0.393 ---------\n",
      "Training Error 12975.860284161336\n",
      "Testing Error 18515.15721016588\n",
      "--------------------\n",
      "---------- Alpha 0.394 ---------\n",
      "Training Error 12977.212546915829\n",
      "Testing Error 18516.10508685713\n",
      "--------------------\n",
      "---------- Alpha 0.395 ---------\n",
      "Training Error 12978.560980386155\n",
      "Testing Error 18517.04955011339\n",
      "--------------------\n",
      "---------- Alpha 0.396 ---------\n",
      "Training Error 12979.912077591203\n",
      "Testing Error 18517.990614233502\n",
      "--------------------\n",
      "---------- Alpha 0.397 ---------\n",
      "Training Error 12981.260393334123\n",
      "Testing Error 18518.92829343584\n",
      "--------------------\n",
      "---------- Alpha 0.398 ---------\n",
      "Training Error 12982.604909330932\n",
      "Testing Error 18519.86260185873\n",
      "--------------------\n",
      "---------- Alpha 0.399 ---------\n",
      "Training Error 12983.945641462255\n",
      "Testing Error 18520.796979086517\n",
      "--------------------\n",
      "---------- Alpha 0.4 ---------\n",
      "Training Error 12985.282605517572\n",
      "Testing Error 18521.742423946176\n",
      "--------------------\n",
      "---------- Alpha 0.401 ---------\n",
      "Training Error 12986.615817195923\n",
      "Testing Error 18522.68449494545\n",
      "--------------------\n",
      "---------- Alpha 0.402 ---------\n",
      "Training Error 12987.95025333432\n",
      "Testing Error 18523.6232060589\n",
      "--------------------\n",
      "---------- Alpha 0.403 ---------\n",
      "Training Error 12989.287688285664\n",
      "Testing Error 18524.558571183283\n",
      "--------------------\n",
      "---------- Alpha 0.404 ---------\n",
      "Training Error 12990.621386139332\n",
      "Testing Error 18525.490604137907\n",
      "--------------------\n",
      "---------- Alpha 0.405 ---------\n",
      "Training Error 12991.951362366262\n",
      "Testing Error 18526.41931866547\n",
      "--------------------\n",
      "---------- Alpha 0.406 ---------\n",
      "Training Error 12993.277632349436\n",
      "Testing Error 18527.344728432334\n",
      "--------------------\n",
      "---------- Alpha 0.407 ---------\n",
      "Training Error 12994.60021138454\n",
      "Testing Error 18528.266847029125\n",
      "--------------------\n",
      "---------- Alpha 0.408 ---------\n",
      "Training Error 12995.91911468067\n",
      "Testing Error 18529.185687971487\n",
      "--------------------\n",
      "---------- Alpha 0.409 ---------\n",
      "Training Error 12997.234357360836\n",
      "Testing Error 18530.10126470016\n",
      "--------------------\n",
      "---------- Alpha 0.41 ---------\n",
      "Training Error 12998.54595446273\n",
      "Testing Error 18531.013590582003\n",
      "--------------------\n",
      "---------- Alpha 0.411 ---------\n",
      "Training Error 12999.853920939171\n",
      "Testing Error 18531.92267891008\n",
      "--------------------\n",
      "---------- Alpha 0.412 ---------\n",
      "Training Error 13001.15827165894\n",
      "Testing Error 18532.82854290464\n",
      "--------------------\n",
      "---------- Alpha 0.413 ---------\n",
      "Training Error 13002.459021407136\n",
      "Testing Error 18533.731195712993\n",
      "--------------------\n",
      "---------- Alpha 0.414 ---------\n",
      "Training Error 13003.75618488597\n",
      "Testing Error 18534.630650410716\n",
      "--------------------\n",
      "---------- Alpha 0.415 ---------\n",
      "Training Error 13005.049776715256\n",
      "Testing Error 18535.52692000164\n",
      "--------------------\n",
      "---------- Alpha 0.416 ---------\n",
      "Training Error 13006.339811433056\n",
      "Testing Error 18536.420017418644\n",
      "--------------------\n",
      "---------- Alpha 0.417 ---------\n",
      "Training Error 13007.626303496218\n",
      "Testing Error 18537.30995552394\n",
      "--------------------\n",
      "---------- Alpha 0.418 ---------\n",
      "Training Error 13008.90926728102\n",
      "Testing Error 18538.196747109734\n",
      "--------------------\n",
      "---------- Alpha 0.419 ---------\n",
      "Training Error 13010.188717083676\n",
      "Testing Error 18539.080404898614\n",
      "--------------------\n",
      "---------- Alpha 0.42 ---------\n",
      "Training Error 13011.465500000875\n",
      "Testing Error 18539.96094154398\n",
      "--------------------\n",
      "---------- Alpha 0.421 ---------\n",
      "Training Error 13012.739111010978\n",
      "Testing Error 18540.838369630703\n",
      "--------------------\n",
      "---------- Alpha 0.422 ---------\n",
      "Training Error 13014.00924735766\n",
      "Testing Error 18541.712701675482\n",
      "--------------------\n",
      "---------- Alpha 0.423 ---------\n",
      "Training Error 13015.275923014271\n",
      "Testing Error 18542.583950127177\n",
      "--------------------\n",
      "---------- Alpha 0.424 ---------\n",
      "Training Error 13016.539151877096\n",
      "Testing Error 18543.452127367615\n",
      "--------------------\n",
      "---------- Alpha 0.425 ---------\n",
      "Training Error 13017.798947765881\n",
      "Testing Error 18544.317245711733\n",
      "--------------------\n",
      "---------- Alpha 0.426 ---------\n",
      "Training Error 13019.055324424298\n",
      "Testing Error 18545.17931740816\n",
      "--------------------\n",
      "---------- Alpha 0.427 ---------\n",
      "Training Error 13020.308295520583\n",
      "Testing Error 18546.038354639753\n",
      "--------------------\n",
      "---------- Alpha 0.428 ---------\n",
      "Training Error 13021.557874648002\n",
      "Testing Error 18546.894369523878\n",
      "--------------------\n",
      "---------- Alpha 0.429 ---------\n",
      "Training Error 13022.80407532542\n",
      "Testing Error 18547.747374113012\n",
      "--------------------\n",
      "---------- Alpha 0.43 ---------\n",
      "Training Error 13024.04691099776\n",
      "Testing Error 18548.597380394993\n",
      "--------------------\n",
      "---------- Alpha 0.431 ---------\n",
      "Training Error 13025.2863950366\n",
      "Testing Error 18549.44440029366\n",
      "--------------------\n",
      "---------- Alpha 0.432 ---------\n",
      "Training Error 13026.52254074063\n",
      "Testing Error 18550.28844566934\n",
      "--------------------\n",
      "---------- Alpha 0.433 ---------\n",
      "Training Error 13027.755361336114\n",
      "Testing Error 18551.129528318786\n",
      "--------------------\n",
      "---------- Alpha 0.434 ---------\n",
      "Training Error 13028.984869977532\n",
      "Testing Error 18551.967659976355\n",
      "--------------------\n",
      "---------- Alpha 0.435 ---------\n",
      "Training Error 13030.211079747987\n",
      "Testing Error 18552.802852313867\n",
      "--------------------\n",
      "---------- Alpha 0.436 ---------\n",
      "Training Error 13031.434003659642\n",
      "Testing Error 18553.635116941186\n",
      "--------------------\n",
      "---------- Alpha 0.437 ---------\n",
      "Training Error 13032.653654654365\n",
      "Testing Error 18554.464465406658\n",
      "--------------------\n",
      "---------- Alpha 0.438 ---------\n",
      "Training Error 13033.870045604108\n",
      "Testing Error 18555.290909197603\n",
      "--------------------\n",
      "---------- Alpha 0.439 ---------\n",
      "Training Error 13035.083189311365\n",
      "Testing Error 18556.114459740504\n",
      "--------------------\n",
      "---------- Alpha 0.44 ---------\n",
      "Training Error 13036.293098509757\n",
      "Testing Error 18556.935128401772\n",
      "--------------------\n",
      "---------- Alpha 0.441 ---------\n",
      "Training Error 13037.499785864427\n",
      "Testing Error 18557.75292648772\n",
      "--------------------\n",
      "---------- Alpha 0.442 ---------\n",
      "Training Error 13038.703263972544\n",
      "Testing Error 18558.567865245248\n",
      "--------------------\n",
      "---------- Alpha 0.443 ---------\n",
      "Training Error 13039.903545363726\n",
      "Testing Error 18559.379955862303\n",
      "--------------------\n",
      "---------- Alpha 0.444 ---------\n",
      "Training Error 13041.100642500529\n",
      "Testing Error 18560.189209467844\n",
      "--------------------\n",
      "---------- Alpha 0.445 ---------\n",
      "Training Error 13042.294567778983\n",
      "Testing Error 18560.99563713287\n",
      "--------------------\n",
      "---------- Alpha 0.446 ---------\n",
      "Training Error 13043.485333528868\n",
      "Testing Error 18561.799249870182\n",
      "--------------------\n",
      "---------- Alpha 0.447 ---------\n",
      "Training Error 13044.672952014376\n",
      "Testing Error 18562.600058635275\n",
      "--------------------\n",
      "---------- Alpha 0.448 ---------\n",
      "Training Error 13045.868054388455\n",
      "Testing Error 18563.39807432631\n",
      "--------------------\n",
      "---------- Alpha 0.449 ---------\n",
      "Training Error 13047.060216945923\n",
      "Testing Error 18564.19330778484\n",
      "--------------------\n",
      "---------- Alpha 0.45 ---------\n",
      "Training Error 13048.249252934456\n",
      "Testing Error 18564.985769795923\n",
      "--------------------\n",
      "---------- Alpha 0.451 ---------\n",
      "Training Error 13049.45056290286\n",
      "Testing Error 18565.775471088673\n",
      "--------------------\n",
      "---------- Alpha 0.452 ---------\n",
      "Training Error 13050.65489049043\n",
      "Testing Error 18566.562422336476\n",
      "--------------------\n",
      "---------- Alpha 0.453 ---------\n",
      "Training Error 13051.856089106186\n",
      "Testing Error 18567.34663415744\n",
      "--------------------\n",
      "---------- Alpha 0.454 ---------\n",
      "Training Error 13053.054170717061\n",
      "Testing Error 18568.128117114957\n",
      "--------------------\n",
      "---------- Alpha 0.455 ---------\n",
      "Training Error 13054.249147227105\n",
      "Testing Error 18568.90688171748\n",
      "--------------------\n",
      "---------- Alpha 0.456 ---------\n",
      "Training Error 13055.441030478092\n",
      "Testing Error 18569.682938419566\n",
      "--------------------\n",
      "---------- Alpha 0.457 ---------\n",
      "Training Error 13056.635035271587\n",
      "Testing Error 18570.45629762195\n",
      "--------------------\n",
      "---------- Alpha 0.458 ---------\n",
      "Training Error 13057.835658470953\n",
      "Testing Error 18571.226969671578\n",
      "--------------------\n",
      "---------- Alpha 0.459 ---------\n",
      "Training Error 13059.033190009293\n",
      "Testing Error 18571.994964862584\n",
      "--------------------\n",
      "---------- Alpha 0.46 ---------\n",
      "Training Error 13060.22764160203\n",
      "Testing Error 18572.76029343606\n",
      "--------------------\n",
      "---------- Alpha 0.461 ---------\n",
      "Training Error 13061.41902490373\n",
      "Testing Error 18573.522965580803\n",
      "--------------------\n",
      "---------- Alpha 0.462 ---------\n",
      "Training Error 13062.607351508492\n",
      "Testing Error 18574.282991433414\n",
      "--------------------\n",
      "---------- Alpha 0.463 ---------\n",
      "Training Error 13063.792632950335\n",
      "Testing Error 18575.040381078812\n",
      "--------------------\n",
      "---------- Alpha 0.464 ---------\n",
      "Training Error 13064.974880703629\n",
      "Testing Error 18575.795144550437\n",
      "--------------------\n",
      "---------- Alpha 0.465 ---------\n",
      "Training Error 13066.164128257147\n",
      "Testing Error 18576.54729183048\n",
      "--------------------\n",
      "---------- Alpha 0.466 ---------\n",
      "Training Error 13067.35182088878\n",
      "Testing Error 18577.296832850578\n",
      "--------------------\n",
      "---------- Alpha 0.467 ---------\n",
      "Training Error 13068.536491710198\n",
      "Testing Error 18578.043777491872\n",
      "--------------------\n",
      "---------- Alpha 0.468 ---------\n",
      "Training Error 13069.718152036954\n",
      "Testing Error 18578.788135585233\n",
      "--------------------\n",
      "---------- Alpha 0.469 ---------\n",
      "Training Error 13070.896813126488\n",
      "Testing Error 18579.529916911906\n",
      "--------------------\n",
      "---------- Alpha 0.47 ---------\n",
      "Training Error 13072.079715718228\n",
      "Testing Error 18580.269131203713\n",
      "--------------------\n",
      "---------- Alpha 0.471 ---------\n",
      "Training Error 13073.264162412708\n",
      "Testing Error 18581.00578814304\n",
      "--------------------\n",
      "---------- Alpha 0.472 ---------\n",
      "Training Error 13074.445606830132\n",
      "Testing Error 18581.739897363757\n",
      "--------------------\n",
      "---------- Alpha 0.473 ---------\n",
      "Training Error 13075.624060137969\n",
      "Testing Error 18582.471468450887\n",
      "--------------------\n",
      "---------- Alpha 0.474 ---------\n",
      "Training Error 13076.807205990926\n",
      "Testing Error 18583.200510941548\n",
      "--------------------\n",
      "---------- Alpha 0.475 ---------\n",
      "Training Error 13077.987816654191\n",
      "Testing Error 18583.927034324846\n",
      "--------------------\n",
      "---------- Alpha 0.476 ---------\n",
      "Training Error 13079.165451828569\n",
      "Testing Error 18584.651048041917\n",
      "--------------------\n",
      "---------- Alpha 0.477 ---------\n",
      "Training Error 13080.34012252071\n",
      "Testing Error 18585.37256148725\n",
      "--------------------\n",
      "---------- Alpha 0.478 ---------\n",
      "Training Error 13081.511839681221\n",
      "Testing Error 18586.091584007867\n",
      "--------------------\n",
      "---------- Alpha 0.479 ---------\n",
      "Training Error 13082.680614205496\n",
      "Testing Error 18586.808124904204\n",
      "--------------------\n",
      "---------- Alpha 0.48 ---------\n",
      "Training Error 13083.846456933774\n",
      "Testing Error 18587.52219343037\n",
      "--------------------\n",
      "---------- Alpha 0.481 ---------\n",
      "Training Error 13085.009378651643\n",
      "Testing Error 18588.23379879422\n",
      "--------------------\n",
      "---------- Alpha 0.482 ---------\n",
      "Training Error 13086.169390090368\n",
      "Testing Error 18588.942950157965\n",
      "--------------------\n",
      "---------- Alpha 0.483 ---------\n",
      "Training Error 13087.326501927178\n",
      "Testing Error 18589.649656638096\n",
      "--------------------\n",
      "---------- Alpha 0.484 ---------\n",
      "Training Error 13088.480724785686\n",
      "Testing Error 18590.353927305976\n",
      "--------------------\n",
      "---------- Alpha 0.485 ---------\n",
      "Training Error 13089.632069236226\n",
      "Testing Error 18591.066890618597\n",
      "--------------------\n",
      "---------- Alpha 0.486 ---------\n",
      "Training Error 13090.785441262498\n",
      "Testing Error 18591.79198576569\n",
      "--------------------\n",
      "---------- Alpha 0.487 ---------\n",
      "Training Error 13091.94587318338\n",
      "Testing Error 18592.514619024845\n",
      "--------------------\n",
      "---------- Alpha 0.488 ---------\n",
      "Training Error 13093.103429294264\n",
      "Testing Error 18593.234799486392\n",
      "--------------------\n",
      "---------- Alpha 0.489 ---------\n",
      "Training Error 13094.258120049768\n",
      "Testing Error 18593.952536195662\n",
      "--------------------\n",
      "---------- Alpha 0.49 ---------\n",
      "Training Error 13095.409955852532\n",
      "Testing Error 18594.667838153644\n",
      "--------------------\n",
      "---------- Alpha 0.491 ---------\n",
      "Training Error 13096.558947053369\n",
      "Testing Error 18595.380714316827\n",
      "--------------------\n",
      "---------- Alpha 0.492 ---------\n",
      "Training Error 13097.705103951805\n",
      "Testing Error 18596.09580017308\n",
      "--------------------\n",
      "---------- Alpha 0.493 ---------\n",
      "Training Error 13098.84843679618\n",
      "Testing Error 18596.814642897112\n",
      "--------------------\n",
      "---------- Alpha 0.494 ---------\n",
      "Training Error 13099.988955784103\n",
      "Testing Error 18597.531057840446\n",
      "--------------------\n",
      "---------- Alpha 0.495 ---------\n",
      "Training Error 13101.126671062837\n",
      "Testing Error 18598.245053897677\n",
      "--------------------\n",
      "---------- Alpha 0.496 ---------\n",
      "Training Error 13102.261592729397\n",
      "Testing Error 18598.956639919656\n",
      "--------------------\n",
      "---------- Alpha 0.497 ---------\n",
      "Training Error 13103.39373083109\n",
      "Testing Error 18599.66582471422\n",
      "--------------------\n",
      "---------- Alpha 0.498 ---------\n",
      "Training Error 13104.528074385187\n",
      "Testing Error 18600.372617046152\n",
      "--------------------\n",
      "---------- Alpha 0.499 ---------\n",
      "Training Error 13105.674433195412\n",
      "Testing Error 18601.077025637707\n",
      "--------------------\n",
      "---------- Alpha 0.5 ---------\n",
      "Training Error 13106.817995778987\n",
      "Testing Error 18601.779059168603\n",
      "--------------------\n",
      "---------- Alpha 0.501 ---------\n",
      "Training Error 13107.958772128537\n",
      "Testing Error 18602.4787262766\n",
      "--------------------\n",
      "---------- Alpha 0.502 ---------\n",
      "Training Error 13109.09677218769\n",
      "Testing Error 18603.176035557353\n",
      "--------------------\n",
      "---------- Alpha 0.503 ---------\n",
      "Training Error 13110.23200585153\n",
      "Testing Error 18603.870995565125\n",
      "--------------------\n",
      "---------- Alpha 0.504 ---------\n",
      "Training Error 13111.364482966814\n",
      "Testing Error 18604.563614812694\n",
      "--------------------\n",
      "---------- Alpha 0.505 ---------\n",
      "Training Error 13112.494213332311\n",
      "Testing Error 18605.253901771775\n",
      "--------------------\n",
      "---------- Alpha 0.506 ---------\n",
      "Training Error 13113.621206699025\n",
      "Testing Error 18605.94186487316\n",
      "--------------------\n",
      "---------- Alpha 0.507 ---------\n",
      "Training Error 13114.745472770619\n",
      "Testing Error 18606.627512507126\n",
      "--------------------\n",
      "---------- Alpha 0.508 ---------\n",
      "Training Error 13115.867021203625\n",
      "Testing Error 18607.310853023555\n",
      "--------------------\n",
      "---------- Alpha 0.509 ---------\n",
      "Training Error 13116.999372808981\n",
      "Testing Error 18607.99189473224\n",
      "--------------------\n",
      "---------- Alpha 0.51 ---------\n",
      "Training Error 13118.145451946002\n",
      "Testing Error 18608.67064590294\n",
      "--------------------\n",
      "---------- Alpha 0.511 ---------\n",
      "Training Error 13119.288775784631\n",
      "Testing Error 18609.347114766082\n",
      "--------------------\n",
      "---------- Alpha 0.512 ---------\n",
      "Training Error 13120.42935402154\n",
      "Testing Error 18610.021309512522\n",
      "--------------------\n",
      "---------- Alpha 0.513 ---------\n",
      "Training Error 13121.567196306683\n",
      "Testing Error 18610.693238293934\n",
      "--------------------\n",
      "---------- Alpha 0.514 ---------\n",
      "Training Error 13122.702312243604\n",
      "Testing Error 18611.362909223215\n",
      "--------------------\n",
      "---------- Alpha 0.515 ---------\n",
      "Training Error 13123.834711389656\n",
      "Testing Error 18612.030330374546\n",
      "--------------------\n",
      "---------- Alpha 0.516 ---------\n",
      "Training Error 13124.964403256361\n",
      "Testing Error 18612.695509783553\n",
      "--------------------\n",
      "---------- Alpha 0.517 ---------\n",
      "Training Error 13126.091397309592\n",
      "Testing Error 18613.358455447877\n",
      "--------------------\n",
      "---------- Alpha 0.518 ---------\n",
      "Training Error 13127.21570297\n",
      "Testing Error 18614.019175327005\n",
      "--------------------\n",
      "---------- Alpha 0.519 ---------\n",
      "Training Error 13128.337329613065\n",
      "Testing Error 18614.677677342683\n",
      "--------------------\n",
      "---------- Alpha 0.52 ---------\n",
      "Training Error 13129.460297899883\n",
      "Testing Error 18615.33396937929\n",
      "--------------------\n",
      "---------- Alpha 0.521 ---------\n",
      "Training Error 13130.580805907523\n",
      "Testing Error 18615.988059283733\n",
      "--------------------\n",
      "---------- Alpha 0.522 ---------\n",
      "Training Error 13131.69866035838\n",
      "Testing Error 18616.63995486593\n",
      "--------------------\n",
      "---------- Alpha 0.523 ---------\n",
      "Training Error 13132.813870454072\n",
      "Testing Error 18617.289663898966\n",
      "--------------------\n",
      "---------- Alpha 0.524 ---------\n",
      "Training Error 13133.926445352534\n",
      "Testing Error 18617.937194119324\n",
      "--------------------\n",
      "---------- Alpha 0.525 ---------\n",
      "Training Error 13135.036394168275\n",
      "Testing Error 18618.582553226934\n",
      "--------------------\n",
      "---------- Alpha 0.526 ---------\n",
      "Training Error 13136.143725972643\n",
      "Testing Error 18619.225748885634\n",
      "--------------------\n",
      "---------- Alpha 0.527 ---------\n",
      "Training Error 13137.248449794059\n",
      "Testing Error 18619.866788723368\n",
      "--------------------\n",
      "---------- Alpha 0.528 ---------\n",
      "Training Error 13138.350574618307\n",
      "Testing Error 18620.505680332102\n",
      "--------------------\n",
      "---------- Alpha 0.529 ---------\n",
      "Training Error 13139.450109388827\n",
      "Testing Error 18621.1424312685\n",
      "--------------------\n",
      "---------- Alpha 0.53 ---------\n",
      "Training Error 13140.54706300688\n",
      "Testing Error 18621.77704905372\n",
      "--------------------\n",
      "---------- Alpha 0.531 ---------\n",
      "Training Error 13141.641444331863\n",
      "Testing Error 18622.409541173813\n",
      "--------------------\n",
      "---------- Alpha 0.532 ---------\n",
      "Training Error 13142.733262181531\n",
      "Testing Error 18623.03991507998\n",
      "--------------------\n",
      "---------- Alpha 0.533 ---------\n",
      "Training Error 13143.822525332314\n",
      "Testing Error 18623.668178188622\n",
      "--------------------\n",
      "---------- Alpha 0.534 ---------\n",
      "Training Error 13144.90924251944\n",
      "Testing Error 18624.294337881656\n",
      "--------------------\n",
      "---------- Alpha 0.535 ---------\n",
      "Training Error 13145.99342243731\n",
      "Testing Error 18624.918401506744\n",
      "--------------------\n",
      "---------- Alpha 0.536 ---------\n",
      "Training Error 13147.075073739676\n",
      "Testing Error 18625.540376377427\n",
      "--------------------\n",
      "---------- Alpha 0.537 ---------\n",
      "Training Error 13148.154205039882\n",
      "Testing Error 18626.160269773278\n",
      "--------------------\n",
      "---------- Alpha 0.538 ---------\n",
      "Training Error 13149.230824911112\n",
      "Testing Error 18626.77808894029\n",
      "--------------------\n",
      "---------- Alpha 0.539 ---------\n",
      "Training Error 13150.304941886678\n",
      "Testing Error 18627.393841090805\n",
      "--------------------\n",
      "---------- Alpha 0.54 ---------\n",
      "Training Error 13151.376564460115\n",
      "Testing Error 18628.00753340395\n",
      "--------------------\n",
      "---------- Alpha 0.541 ---------\n",
      "Training Error 13152.445701085631\n",
      "Testing Error 18628.619173025698\n",
      "--------------------\n",
      "---------- Alpha 0.542 ---------\n",
      "Training Error 13153.512360178152\n",
      "Testing Error 18629.228767069122\n",
      "--------------------\n",
      "---------- Alpha 0.543 ---------\n",
      "Training Error 13154.57655011364\n",
      "Testing Error 18629.836322614578\n",
      "--------------------\n",
      "---------- Alpha 0.544 ---------\n",
      "Training Error 13155.638279229359\n",
      "Testing Error 18630.44184670991\n",
      "--------------------\n",
      "---------- Alpha 0.545 ---------\n",
      "Training Error 13156.697555823963\n",
      "Testing Error 18631.045346370458\n",
      "--------------------\n",
      "---------- Alpha 0.546 ---------\n",
      "Training Error 13157.754388157891\n",
      "Testing Error 18631.646828579647\n",
      "--------------------\n",
      "---------- Alpha 0.547 ---------\n",
      "Training Error 13158.808784453495\n",
      "Testing Error 18632.246300288753\n",
      "--------------------\n",
      "---------- Alpha 0.548 ---------\n",
      "Training Error 13159.860752895274\n",
      "Testing Error 18632.843768417246\n",
      "--------------------\n",
      "---------- Alpha 0.549 ---------\n",
      "Training Error 13160.9103016301\n",
      "Testing Error 18633.439239853156\n",
      "--------------------\n",
      "---------- Alpha 0.55 ---------\n",
      "Training Error 13161.958366597804\n",
      "Testing Error 18634.03272145292\n",
      "--------------------\n",
      "---------- Alpha 0.551 ---------\n",
      "Training Error 13163.006783165034\n",
      "Testing Error 18634.624220041933\n",
      "--------------------\n",
      "---------- Alpha 0.552 ---------\n",
      "Training Error 13164.05280638052\n",
      "Testing Error 18635.213742414344\n",
      "--------------------\n",
      "---------- Alpha 0.553 ---------\n",
      "Training Error 13165.096444218427\n",
      "Testing Error 18635.80129533353\n",
      "--------------------\n",
      "---------- Alpha 0.554 ---------\n",
      "Training Error 13166.137704616498\n",
      "Testing Error 18636.386885532047\n",
      "--------------------\n",
      "---------- Alpha 0.555 ---------\n",
      "Training Error 13167.17659547639\n",
      "Testing Error 18636.97051971208\n",
      "--------------------\n",
      "---------- Alpha 0.556 ---------\n",
      "Training Error 13168.213124663806\n",
      "Testing Error 18637.552204545453\n",
      "--------------------\n",
      "---------- Alpha 0.557 ---------\n",
      "Training Error 13169.24730000865\n",
      "Testing Error 18638.131946673682\n",
      "--------------------\n",
      "---------- Alpha 0.558 ---------\n",
      "Training Error 13170.279129305414\n",
      "Testing Error 18638.709752708408\n",
      "--------------------\n",
      "---------- Alpha 0.559 ---------\n",
      "Training Error 13171.308620313166\n",
      "Testing Error 18639.285629231366\n",
      "--------------------\n",
      "---------- Alpha 0.56 ---------\n",
      "Training Error 13172.335780755935\n",
      "Testing Error 18639.859582794772\n",
      "--------------------\n",
      "---------- Alpha 0.561 ---------\n",
      "Training Error 13173.3606183228\n",
      "Testing Error 18640.43161992114\n",
      "--------------------\n",
      "---------- Alpha 0.562 ---------\n",
      "Training Error 13174.383140668126\n",
      "Testing Error 18641.001747103786\n",
      "--------------------\n",
      "---------- Alpha 0.563 ---------\n",
      "Training Error 13175.40680023263\n",
      "Testing Error 18641.569970806864\n",
      "--------------------\n",
      "---------- Alpha 0.564 ---------\n",
      "Training Error 13176.43074666433\n",
      "Testing Error 18642.136297465586\n",
      "--------------------\n",
      "---------- Alpha 0.565 ---------\n",
      "Training Error 13177.452389236865\n",
      "Testing Error 18642.71559131053\n",
      "--------------------\n",
      "---------- Alpha 0.566 ---------\n",
      "Training Error 13178.474320315603\n",
      "Testing Error 18643.307482564196\n",
      "--------------------\n",
      "---------- Alpha 0.567 ---------\n",
      "Training Error 13179.497572082108\n",
      "Testing Error 18643.89747565567\n",
      "--------------------\n",
      "---------- Alpha 0.568 ---------\n",
      "Training Error 13180.518539671297\n",
      "Testing Error 18644.48557688355\n",
      "--------------------\n",
      "---------- Alpha 0.569 ---------\n",
      "Training Error 13181.537230539014\n",
      "Testing Error 18645.071792518425\n",
      "--------------------\n",
      "---------- Alpha 0.57 ---------\n",
      "Training Error 13182.55365210787\n",
      "Testing Error 18645.656128803377\n",
      "--------------------\n",
      "---------- Alpha 0.571 ---------\n",
      "Training Error 13183.567811767367\n",
      "Testing Error 18646.23859195408\n",
      "--------------------\n",
      "---------- Alpha 0.572 ---------\n",
      "Training Error 13184.579716874036\n",
      "Testing Error 18646.81918815861\n",
      "--------------------\n",
      "---------- Alpha 0.573 ---------\n",
      "Training Error 13185.589374751666\n",
      "Testing Error 18647.39792357796\n",
      "--------------------\n",
      "---------- Alpha 0.574 ---------\n",
      "Training Error 13186.596792691562\n",
      "Testing Error 18647.974804346155\n",
      "--------------------\n",
      "---------- Alpha 0.575 ---------\n",
      "Training Error 13187.60197795257\n",
      "Testing Error 18648.549836570124\n",
      "--------------------\n",
      "---------- Alpha 0.576 ---------\n",
      "Training Error 13188.604937761407\n",
      "Testing Error 18649.123026330217\n",
      "--------------------\n",
      "---------- Alpha 0.577 ---------\n",
      "Training Error 13189.605679312785\n",
      "Testing Error 18649.69437968013\n",
      "--------------------\n",
      "---------- Alpha 0.578 ---------\n",
      "Training Error 13190.618400875044\n",
      "Testing Error 18650.263902647093\n",
      "--------------------\n",
      "---------- Alpha 0.579 ---------\n",
      "Training Error 13191.63599048461\n",
      "Testing Error 18650.831601232025\n",
      "--------------------\n",
      "---------- Alpha 0.58 ---------\n",
      "Training Error 13192.651345750406\n",
      "Testing Error 18651.3974814097\n",
      "--------------------\n",
      "---------- Alpha 0.581 ---------\n",
      "Training Error 13193.664473847948\n",
      "Testing Error 18651.96154912883\n",
      "--------------------\n",
      "---------- Alpha 0.582 ---------\n",
      "Training Error 13194.67538192128\n",
      "Testing Error 18652.523810312396\n",
      "--------------------\n",
      "---------- Alpha 0.583 ---------\n",
      "Training Error 13195.684077083019\n",
      "Testing Error 18653.08427085746\n",
      "--------------------\n",
      "---------- Alpha 0.584 ---------\n",
      "Training Error 13196.690566414612\n",
      "Testing Error 18653.642936635686\n",
      "--------------------\n",
      "---------- Alpha 0.585 ---------\n",
      "Training Error 13197.69485696649\n",
      "Testing Error 18654.19981349308\n",
      "--------------------\n",
      "---------- Alpha 0.586 ---------\n",
      "Training Error 13198.696955758267\n",
      "Testing Error 18654.7549072506\n",
      "--------------------\n",
      "---------- Alpha 0.587 ---------\n",
      "Training Error 13199.696869778849\n",
      "Testing Error 18655.308223703734\n",
      "--------------------\n",
      "---------- Alpha 0.588 ---------\n",
      "Training Error 13200.694605986704\n",
      "Testing Error 18655.859768623268\n",
      "--------------------\n",
      "---------- Alpha 0.589 ---------\n",
      "Training Error 13201.690171309925\n",
      "Testing Error 18656.409547754876\n",
      "--------------------\n",
      "---------- Alpha 0.59 ---------\n",
      "Training Error 13202.68357264647\n",
      "Testing Error 18656.957566819518\n",
      "--------------------\n",
      "---------- Alpha 0.591 ---------\n",
      "Training Error 13203.674816864275\n",
      "Testing Error 18657.503831513535\n",
      "--------------------\n",
      "---------- Alpha 0.592 ---------\n",
      "Training Error 13204.663910801522\n",
      "Testing Error 18658.04834750888\n",
      "--------------------\n",
      "---------- Alpha 0.593 ---------\n",
      "Training Error 13205.650861266655\n",
      "Testing Error 18658.591120453028\n",
      "--------------------\n",
      "---------- Alpha 0.594 ---------\n",
      "Training Error 13206.635675038699\n",
      "Testing Error 18659.132155969317\n",
      "--------------------\n",
      "---------- Alpha 0.595 ---------\n",
      "Training Error 13207.618358867276\n",
      "Testing Error 18659.67145965692\n",
      "--------------------\n",
      "---------- Alpha 0.596 ---------\n",
      "Training Error 13208.598919472903\n",
      "Testing Error 18660.302353793846\n",
      "--------------------\n",
      "---------- Alpha 0.597 ---------\n",
      "Training Error 13209.577363547052\n",
      "Testing Error 18661.011567744335\n",
      "--------------------\n",
      "---------- Alpha 0.598 ---------\n",
      "Training Error 13210.553697752364\n",
      "Testing Error 18661.718870405242\n",
      "--------------------\n",
      "---------- Alpha 0.599 ---------\n",
      "Training Error 13211.537423017333\n",
      "Testing Error 18662.424267592876\n",
      "--------------------\n",
      "---------- Alpha 0.6 ---------\n",
      "Training Error 13212.520571281964\n",
      "Testing Error 18663.127765099736\n",
      "--------------------\n",
      "---------- Alpha 0.601 ---------\n",
      "Training Error 13213.501609786867\n",
      "Testing Error 18663.829368694736\n",
      "--------------------\n",
      "---------- Alpha 0.602 ---------\n",
      "Training Error 13214.480545143118\n",
      "Testing Error 18664.529084123085\n",
      "--------------------\n",
      "---------- Alpha 0.603 ---------\n",
      "Training Error 13215.457383933439\n",
      "Testing Error 18665.22691710644\n",
      "--------------------\n",
      "---------- Alpha 0.604 ---------\n",
      "Training Error 13216.432132712396\n",
      "Testing Error 18665.922873343272\n",
      "--------------------\n",
      "---------- Alpha 0.605 ---------\n",
      "Training Error 13217.404798006515\n",
      "Testing Error 18666.616958508675\n",
      "--------------------\n",
      "---------- Alpha 0.606 ---------\n",
      "Training Error 13218.3753863145\n",
      "Testing Error 18667.309178254854\n",
      "--------------------\n",
      "---------- Alpha 0.607 ---------\n",
      "Training Error 13219.343904107294\n",
      "Testing Error 18667.99953821078\n",
      "--------------------\n",
      "---------- Alpha 0.608 ---------\n",
      "Training Error 13220.31035782827\n",
      "Testing Error 18668.688043982733\n",
      "--------------------\n",
      "---------- Alpha 0.609 ---------\n",
      "Training Error 13221.274753893396\n",
      "Testing Error 18669.37470115417\n",
      "--------------------\n",
      "---------- Alpha 0.61 ---------\n",
      "Training Error 13222.237098691394\n",
      "Testing Error 18670.059515285953\n",
      "--------------------\n",
      "---------- Alpha 0.611 ---------\n",
      "Training Error 13223.197398583812\n",
      "Testing Error 18670.742491916404\n",
      "--------------------\n",
      "---------- Alpha 0.612 ---------\n",
      "Training Error 13224.155659905238\n",
      "Testing Error 18671.42363656137\n",
      "--------------------\n",
      "---------- Alpha 0.613 ---------\n",
      "Training Error 13225.111888963464\n",
      "Testing Error 18672.10295471461\n",
      "--------------------\n",
      "---------- Alpha 0.614 ---------\n",
      "Training Error 13226.066092039597\n",
      "Testing Error 18672.78045184769\n",
      "--------------------\n",
      "---------- Alpha 0.615 ---------\n",
      "Training Error 13227.018275388153\n",
      "Testing Error 18673.456133409953\n",
      "--------------------\n",
      "---------- Alpha 0.616 ---------\n",
      "Training Error 13227.96844523732\n",
      "Testing Error 18674.13000482895\n",
      "--------------------\n",
      "---------- Alpha 0.617 ---------\n",
      "Training Error 13228.919999554244\n",
      "Testing Error 18674.8020715104\n",
      "--------------------\n",
      "---------- Alpha 0.618 ---------\n",
      "Training Error 13229.872360303234\n",
      "Testing Error 18675.47233883824\n",
      "--------------------\n",
      "---------- Alpha 0.619 ---------\n",
      "Training Error 13230.822720461581\n",
      "Testing Error 18676.1408121749\n",
      "--------------------\n",
      "---------- Alpha 0.62 ---------\n",
      "Training Error 13231.77108616252\n",
      "Testing Error 18676.807496861333\n",
      "--------------------\n",
      "---------- Alpha 0.621 ---------\n",
      "Training Error 13232.717463513485\n",
      "Testing Error 18677.472398216938\n",
      "--------------------\n",
      "---------- Alpha 0.622 ---------\n",
      "Training Error 13233.661858596419\n",
      "Testing Error 18678.135521540087\n",
      "--------------------\n",
      "---------- Alpha 0.623 ---------\n",
      "Training Error 13234.604277467726\n",
      "Testing Error 18678.796872107818\n",
      "--------------------\n",
      "---------- Alpha 0.624 ---------\n",
      "Training Error 13235.544726158578\n",
      "Testing Error 18679.456455176238\n",
      "--------------------\n",
      "---------- Alpha 0.625 ---------\n",
      "Training Error 13236.483210674935\n",
      "Testing Error 18680.114275980417\n",
      "--------------------\n",
      "---------- Alpha 0.626 ---------\n",
      "Training Error 13237.41973699774\n",
      "Testing Error 18680.770339734656\n",
      "--------------------\n",
      "---------- Alpha 0.627 ---------\n",
      "Training Error 13238.358584089347\n",
      "Testing Error 18681.424651632507\n",
      "--------------------\n",
      "---------- Alpha 0.628 ---------\n",
      "Training Error 13239.297317501474\n",
      "Testing Error 18682.077216846883\n",
      "--------------------\n",
      "---------- Alpha 0.629 ---------\n",
      "Training Error 13240.2341010433\n",
      "Testing Error 18682.728040530117\n",
      "--------------------\n",
      "---------- Alpha 0.63 ---------\n",
      "Training Error 13241.168940621294\n",
      "Testing Error 18683.377127814318\n",
      "--------------------\n",
      "---------- Alpha 0.631 ---------\n",
      "Training Error 13242.101842117496\n",
      "Testing Error 18684.027532355656\n",
      "--------------------\n",
      "---------- Alpha 0.632 ---------\n",
      "Training Error 13243.032811389532\n",
      "Testing Error 18684.696281063058\n",
      "--------------------\n",
      "---------- Alpha 0.633 ---------\n",
      "Training Error 13243.961854270834\n",
      "Testing Error 18685.36326480558\n",
      "--------------------\n",
      "---------- Alpha 0.634 ---------\n",
      "Training Error 13244.88897657077\n",
      "Testing Error 18686.02848877574\n",
      "--------------------\n",
      "---------- Alpha 0.635 ---------\n",
      "Training Error 13245.814184074694\n",
      "Testing Error 18686.691958145588\n",
      "--------------------\n",
      "---------- Alpha 0.636 ---------\n",
      "Training Error 13246.73748254419\n",
      "Testing Error 18687.353678066764\n",
      "--------------------\n",
      "---------- Alpha 0.637 ---------\n",
      "Training Error 13247.660160281375\n",
      "Testing Error 18688.01365367048\n",
      "--------------------\n",
      "---------- Alpha 0.638 ---------\n",
      "Training Error 13248.588750526575\n",
      "Testing Error 18688.671890067908\n",
      "--------------------\n",
      "---------- Alpha 0.639 ---------\n",
      "Training Error 13249.518747754873\n",
      "Testing Error 18689.32839234997\n",
      "--------------------\n",
      "---------- Alpha 0.64 ---------\n",
      "Training Error 13250.447203861317\n",
      "Testing Error 18689.983165587637\n",
      "--------------------\n",
      "---------- Alpha 0.641 ---------\n",
      "Training Error 13251.373765057335\n",
      "Testing Error 18690.636214831964\n",
      "--------------------\n",
      "---------- Alpha 0.642 ---------\n",
      "Training Error 13252.298436993522\n",
      "Testing Error 18691.287545114315\n",
      "--------------------\n",
      "---------- Alpha 0.643 ---------\n",
      "Training Error 13253.221225297304\n",
      "Testing Error 18691.937161446047\n",
      "--------------------\n",
      "---------- Alpha 0.644 ---------\n",
      "Training Error 13254.142135573305\n",
      "Testing Error 18692.58868274538\n",
      "--------------------\n",
      "---------- Alpha 0.645 ---------\n",
      "Training Error 13255.061173403177\n",
      "Testing Error 18693.25464938392\n",
      "--------------------\n",
      "---------- Alpha 0.646 ---------\n",
      "Training Error 13255.978344345931\n",
      "Testing Error 18693.918877551227\n",
      "--------------------\n",
      "---------- Alpha 0.647 ---------\n",
      "Training Error 13256.893653937976\n",
      "Testing Error 18694.581372310673\n",
      "--------------------\n",
      "---------- Alpha 0.648 ---------\n",
      "Training Error 13257.807107693216\n",
      "Testing Error 18695.242138705817\n",
      "--------------------\n",
      "---------- Alpha 0.649 ---------\n",
      "Training Error 13258.718711103204\n",
      "Testing Error 18695.90118176052\n",
      "--------------------\n",
      "---------- Alpha 0.65 ---------\n",
      "Training Error 13259.62846963726\n",
      "Testing Error 18696.55850647916\n",
      "--------------------\n",
      "---------- Alpha 0.651 ---------\n",
      "Training Error 13260.536388742546\n",
      "Testing Error 18697.214117846477\n",
      "--------------------\n",
      "---------- Alpha 0.652 ---------\n",
      "Training Error 13261.45270657387\n",
      "Testing Error 18697.86802082792\n",
      "--------------------\n",
      "---------- Alpha 0.653 ---------\n",
      "Training Error 13262.376868628342\n",
      "Testing Error 18698.520220369606\n",
      "--------------------\n",
      "---------- Alpha 0.654 ---------\n",
      "Training Error 13263.299184746433\n",
      "Testing Error 18699.170721398372\n",
      "--------------------\n",
      "---------- Alpha 0.655 ---------\n",
      "Training Error 13264.219660336921\n",
      "Testing Error 18699.819528822012\n",
      "--------------------\n",
      "---------- Alpha 0.656 ---------\n",
      "Training Error 13265.138300786759\n",
      "Testing Error 18700.466647529254\n",
      "--------------------\n",
      "---------- Alpha 0.657 ---------\n",
      "Training Error 13266.06625806158\n",
      "Testing Error 18701.112082390013\n",
      "--------------------\n",
      "---------- Alpha 0.658 ---------\n",
      "Training Error 13266.995394642589\n",
      "Testing Error 18701.755838255205\n",
      "--------------------\n",
      "---------- Alpha 0.659 ---------\n",
      "Training Error 13267.922688613107\n",
      "Testing Error 18702.3979199572\n",
      "--------------------\n",
      "---------- Alpha 0.66 ---------\n",
      "Training Error 13268.848145339009\n",
      "Testing Error 18703.038332309516\n",
      "--------------------\n",
      "---------- Alpha 0.661 ---------\n",
      "Training Error 13269.771770164763\n",
      "Testing Error 18703.677080107303\n",
      "--------------------\n",
      "---------- Alpha 0.662 ---------\n",
      "Training Error 13270.69356841349\n",
      "Testing Error 18704.314168127163\n",
      "--------------------\n",
      "---------- Alpha 0.663 ---------\n",
      "Training Error 13271.6135453871\n",
      "Testing Error 18704.949601127275\n",
      "--------------------\n",
      "---------- Alpha 0.664 ---------\n",
      "Training Error 13272.531706366437\n",
      "Testing Error 18705.58338384773\n",
      "--------------------\n",
      "---------- Alpha 0.665 ---------\n",
      "Training Error 13273.44805661129\n",
      "Testing Error 18706.21552101013\n",
      "--------------------\n",
      "---------- Alpha 0.666 ---------\n",
      "Training Error 13274.362601360584\n",
      "Testing Error 18706.84601731821\n",
      "--------------------\n",
      "---------- Alpha 0.667 ---------\n",
      "Training Error 13275.275345832482\n",
      "Testing Error 18707.474877457713\n",
      "--------------------\n",
      "---------- Alpha 0.668 ---------\n",
      "Training Error 13276.186295224456\n",
      "Testing Error 18708.10210609628\n",
      "--------------------\n",
      "---------- Alpha 0.669 ---------\n",
      "Training Error 13277.095454713355\n",
      "Testing Error 18708.72770788384\n",
      "--------------------\n",
      "---------- Alpha 0.67 ---------\n",
      "Training Error 13278.002829455634\n",
      "Testing Error 18709.351687452516\n",
      "--------------------\n",
      "---------- Alpha 0.671 ---------\n",
      "Training Error 13278.908424587331\n",
      "Testing Error 18709.97404941682\n",
      "--------------------\n",
      "---------- Alpha 0.672 ---------\n",
      "Training Error 13279.81224522425\n",
      "Testing Error 18710.59479837365\n",
      "--------------------\n",
      "---------- Alpha 0.673 ---------\n",
      "Training Error 13280.714296462007\n",
      "Testing Error 18711.2139389024\n",
      "--------------------\n",
      "---------- Alpha 0.674 ---------\n",
      "Training Error 13281.614583376153\n",
      "Testing Error 18711.83147556511\n",
      "--------------------\n",
      "---------- Alpha 0.675 ---------\n",
      "Training Error 13282.513111022326\n",
      "Testing Error 18712.4474129064\n",
      "--------------------\n",
      "---------- Alpha 0.676 ---------\n",
      "Training Error 13283.409884436276\n",
      "Testing Error 18713.061755453862\n",
      "--------------------\n",
      "---------- Alpha 0.677 ---------\n",
      "Training Error 13284.304908633963\n",
      "Testing Error 18713.674507717657\n",
      "--------------------\n",
      "---------- Alpha 0.678 ---------\n",
      "Training Error 13285.19818861173\n",
      "Testing Error 18714.28567419104\n",
      "--------------------\n",
      "---------- Alpha 0.679 ---------\n",
      "Training Error 13286.08972934634\n",
      "Testing Error 18714.895259350295\n",
      "--------------------\n",
      "---------- Alpha 0.68 ---------\n",
      "Training Error 13286.97953579512\n",
      "Testing Error 18715.503267654745\n",
      "--------------------\n",
      "---------- Alpha 0.681 ---------\n",
      "Training Error 13287.867612895974\n",
      "Testing Error 18716.10970354688\n",
      "--------------------\n",
      "---------- Alpha 0.682 ---------\n",
      "Training Error 13288.75396556762\n",
      "Testing Error 18716.714571452463\n",
      "--------------------\n",
      "---------- Alpha 0.683 ---------\n",
      "Training Error 13289.638598709469\n",
      "Testing Error 18717.31787578052\n",
      "--------------------\n",
      "---------- Alpha 0.684 ---------\n",
      "Training Error 13290.521517202016\n",
      "Testing Error 18717.919620923778\n",
      "--------------------\n",
      "---------- Alpha 0.685 ---------\n",
      "Training Error 13291.402725906652\n",
      "Testing Error 18718.519811257993\n",
      "--------------------\n",
      "---------- Alpha 0.686 ---------\n",
      "Training Error 13292.282229665941\n",
      "Testing Error 18719.11845114296\n",
      "--------------------\n",
      "---------- Alpha 0.687 ---------\n",
      "Training Error 13293.160033303608\n",
      "Testing Error 18719.71554492182\n",
      "--------------------\n",
      "---------- Alpha 0.688 ---------\n",
      "Training Error 13294.036141624716\n",
      "Testing Error 18720.311096921614\n",
      "--------------------\n",
      "---------- Alpha 0.689 ---------\n",
      "Training Error 13294.910559415699\n",
      "Testing Error 18720.905111453092\n",
      "--------------------\n",
      "---------- Alpha 0.69 ---------\n",
      "Training Error 13295.78329144445\n",
      "Testing Error 18721.49759281086\n",
      "--------------------\n",
      "---------- Alpha 0.691 ---------\n",
      "Training Error 13296.654342460504\n",
      "Testing Error 18722.088545273695\n",
      "--------------------\n",
      "---------- Alpha 0.692 ---------\n",
      "Training Error 13297.523717194983\n",
      "Testing Error 18722.677973104175\n",
      "--------------------\n",
      "---------- Alpha 0.693 ---------\n",
      "Training Error 13298.391420360836\n",
      "Testing Error 18723.265880549236\n",
      "--------------------\n",
      "---------- Alpha 0.694 ---------\n",
      "Training Error 13299.25745665277\n",
      "Testing Error 18723.852271839725\n",
      "--------------------\n",
      "---------- Alpha 0.695 ---------\n",
      "Training Error 13300.121830747557\n",
      "Testing Error 18724.437151191047\n",
      "--------------------\n",
      "---------- Alpha 0.696 ---------\n",
      "Training Error 13300.984547303851\n",
      "Testing Error 18725.02052280277\n",
      "--------------------\n",
      "---------- Alpha 0.697 ---------\n",
      "Training Error 13301.84561096249\n",
      "Testing Error 18725.60239085885\n",
      "--------------------\n",
      "---------- Alpha 0.698 ---------\n",
      "Training Error 13302.705026346517\n",
      "Testing Error 18726.182759527845\n",
      "--------------------\n",
      "---------- Alpha 0.699 ---------\n",
      "Training Error 13303.562798061246\n",
      "Testing Error 18726.761632962854\n",
      "--------------------\n",
      "---------- Alpha 0.7 ---------\n",
      "Training Error 13304.41893069439\n",
      "Testing Error 18727.339015301623\n",
      "--------------------\n",
      "---------- Alpha 0.701 ---------\n",
      "Training Error 13305.273428816048\n",
      "Testing Error 18727.91491066655\n",
      "--------------------\n",
      "---------- Alpha 0.702 ---------\n",
      "Training Error 13306.126296978964\n",
      "Testing Error 18728.48932316492\n",
      "--------------------\n",
      "---------- Alpha 0.703 ---------\n",
      "Training Error 13306.977539718422\n",
      "Testing Error 18729.062256888643\n",
      "--------------------\n",
      "---------- Alpha 0.704 ---------\n",
      "Training Error 13307.827161552515\n",
      "Testing Error 18729.633715914908\n",
      "--------------------\n",
      "---------- Alpha 0.705 ---------\n",
      "Training Error 13308.675166982019\n",
      "Testing Error 18730.203704305568\n",
      "--------------------\n",
      "---------- Alpha 0.706 ---------\n",
      "Training Error 13309.521560490717\n",
      "Testing Error 18730.772226107732\n",
      "--------------------\n",
      "---------- Alpha 0.707 ---------\n",
      "Training Error 13310.366346545268\n",
      "Testing Error 18731.339285353606\n",
      "--------------------\n",
      "---------- Alpha 0.708 ---------\n",
      "Training Error 13311.20952959542\n",
      "Testing Error 18731.904886060656\n",
      "--------------------\n",
      "---------- Alpha 0.709 ---------\n",
      "Training Error 13312.051114074038\n",
      "Testing Error 18732.469032231438\n",
      "--------------------\n",
      "---------- Alpha 0.71 ---------\n",
      "Training Error 13312.89110439722\n",
      "Testing Error 18733.031727854093\n",
      "--------------------\n",
      "---------- Alpha 0.711 ---------\n",
      "Training Error 13313.729504964353\n",
      "Testing Error 18733.59297690204\n",
      "--------------------\n",
      "---------- Alpha 0.712 ---------\n",
      "Training Error 13314.566320158126\n",
      "Testing Error 18734.152783334113\n",
      "--------------------\n",
      "---------- Alpha 0.713 ---------\n",
      "Training Error 13315.401554344822\n",
      "Testing Error 18734.711151094936\n",
      "--------------------\n",
      "---------- Alpha 0.714 ---------\n",
      "Training Error 13316.235211874147\n",
      "Testing Error 18735.26808411451\n",
      "--------------------\n",
      "---------- Alpha 0.715 ---------\n",
      "Training Error 13317.067297079453\n",
      "Testing Error 18735.82358630855\n",
      "--------------------\n",
      "---------- Alpha 0.716 ---------\n",
      "Training Error 13317.897814277816\n",
      "Testing Error 18736.377661578743\n",
      "--------------------\n",
      "---------- Alpha 0.717 ---------\n",
      "Training Error 13318.727509986957\n",
      "Testing Error 18736.930313812285\n",
      "--------------------\n",
      "---------- Alpha 0.718 ---------\n",
      "Training Error 13319.559691897113\n",
      "Testing Error 18737.48154688249\n",
      "--------------------\n",
      "---------- Alpha 0.719 ---------\n",
      "Training Error 13320.390312424544\n",
      "Testing Error 18738.031364648563\n",
      "--------------------\n",
      "---------- Alpha 0.72 ---------\n",
      "Training Error 13321.219375837873\n",
      "Testing Error 18738.5797709556\n",
      "--------------------\n",
      "---------- Alpha 0.721 ---------\n",
      "Training Error 13322.046886389842\n",
      "Testing Error 18739.13827010794\n",
      "--------------------\n",
      "---------- Alpha 0.722 ---------\n",
      "Training Error 13322.872848317249\n",
      "Testing Error 18739.724776407376\n",
      "--------------------\n",
      "---------- Alpha 0.723 ---------\n",
      "Training Error 13323.697936948813\n",
      "Testing Error 18740.309803695072\n",
      "--------------------\n",
      "---------- Alpha 0.724 ---------\n",
      "Training Error 13324.523419588542\n",
      "Testing Error 18740.893355977503\n",
      "--------------------\n",
      "---------- Alpha 0.725 ---------\n",
      "Training Error 13325.34736220102\n",
      "Testing Error 18741.47543724644\n",
      "--------------------\n",
      "---------- Alpha 0.726 ---------\n",
      "Training Error 13326.169768969678\n",
      "Testing Error 18742.056051479398\n",
      "--------------------\n",
      "---------- Alpha 0.727 ---------\n",
      "Training Error 13326.991774454094\n",
      "Testing Error 18742.63520263974\n",
      "--------------------\n",
      "---------- Alpha 0.728 ---------\n",
      "Training Error 13327.817448160564\n",
      "Testing Error 18743.21289467622\n",
      "--------------------\n",
      "---------- Alpha 0.729 ---------\n",
      "Training Error 13328.641591913682\n",
      "Testing Error 18743.789131523565\n",
      "--------------------\n",
      "---------- Alpha 0.73 ---------\n",
      "Training Error 13329.474250244968\n",
      "Testing Error 18744.363917102397\n",
      "--------------------\n",
      "---------- Alpha 0.731 ---------\n",
      "Training Error 13330.30678714629\n",
      "Testing Error 18744.937255319175\n",
      "--------------------\n",
      "---------- Alpha 0.732 ---------\n",
      "Training Error 13331.137804817101\n",
      "Testing Error 18745.5091500664\n",
      "--------------------\n",
      "---------- Alpha 0.733 ---------\n",
      "Training Error 13331.967307309464\n",
      "Testing Error 18746.079605222534\n",
      "--------------------\n",
      "---------- Alpha 0.734 ---------\n",
      "Training Error 13332.795298660667\n",
      "Testing Error 18746.648624652422\n",
      "--------------------\n",
      "---------- Alpha 0.735 ---------\n",
      "Training Error 13333.62178289315\n",
      "Testing Error 18747.216212206793\n",
      "--------------------\n",
      "---------- Alpha 0.736 ---------\n",
      "Training Error 13334.446764014616\n",
      "Testing Error 18747.782371722722\n",
      "--------------------\n",
      "---------- Alpha 0.737 ---------\n",
      "Training Error 13335.270246018155\n",
      "Testing Error 18748.347107023703\n",
      "--------------------\n",
      "---------- Alpha 0.738 ---------\n",
      "Training Error 13336.092232882258\n",
      "Testing Error 18748.910421919485\n",
      "--------------------\n",
      "---------- Alpha 0.739 ---------\n",
      "Training Error 13336.912728570876\n",
      "Testing Error 18749.472320206256\n",
      "--------------------\n",
      "---------- Alpha 0.74 ---------\n",
      "Training Error 13337.731737033544\n",
      "Testing Error 18750.032805666706\n",
      "--------------------\n",
      "---------- Alpha 0.741 ---------\n",
      "Training Error 13338.549262205406\n",
      "Testing Error 18750.59188207013\n",
      "--------------------\n",
      "---------- Alpha 0.742 ---------\n",
      "Training Error 13339.365308007287\n",
      "Testing Error 18751.149553172352\n",
      "--------------------\n",
      "---------- Alpha 0.743 ---------\n",
      "Training Error 13340.179878345769\n",
      "Testing Error 18751.705822716052\n",
      "--------------------\n",
      "---------- Alpha 0.744 ---------\n",
      "Training Error 13340.99297711326\n",
      "Testing Error 18752.260694430384\n",
      "--------------------\n",
      "---------- Alpha 0.745 ---------\n",
      "Training Error 13341.804608188035\n",
      "Testing Error 18752.814172031558\n",
      "--------------------\n",
      "---------- Alpha 0.746 ---------\n",
      "Training Error 13342.614775434331\n",
      "Testing Error 18753.366259222443\n",
      "--------------------\n",
      "---------- Alpha 0.747 ---------\n",
      "Training Error 13343.423482702412\n",
      "Testing Error 18753.91695969297\n",
      "--------------------\n",
      "---------- Alpha 0.748 ---------\n",
      "Training Error 13344.230733828612\n",
      "Testing Error 18754.46627711995\n",
      "--------------------\n",
      "---------- Alpha 0.749 ---------\n",
      "Training Error 13345.036532635382\n",
      "Testing Error 18755.01421516726\n",
      "--------------------\n",
      "---------- Alpha 0.75 ---------\n",
      "Training Error 13345.840882931421\n",
      "Testing Error 18755.56077748587\n",
      "--------------------\n",
      "---------- Alpha 0.751 ---------\n",
      "Training Error 13346.643788511712\n",
      "Testing Error 18756.105967713942\n",
      "--------------------\n",
      "---------- Alpha 0.752 ---------\n",
      "Training Error 13347.445253157515\n",
      "Testing Error 18756.64978947671\n",
      "--------------------\n",
      "---------- Alpha 0.753 ---------\n",
      "Training Error 13348.245280636567\n",
      "Testing Error 18757.192246386967\n",
      "--------------------\n",
      "---------- Alpha 0.754 ---------\n",
      "Training Error 13349.043874702991\n",
      "Testing Error 18757.733342044485\n",
      "--------------------\n",
      "---------- Alpha 0.755 ---------\n",
      "Training Error 13349.841039097488\n",
      "Testing Error 18758.27308003659\n",
      "--------------------\n",
      "---------- Alpha 0.756 ---------\n",
      "Training Error 13350.63677754732\n",
      "Testing Error 18758.81146393803\n",
      "--------------------\n",
      "---------- Alpha 0.757 ---------\n",
      "Training Error 13351.431093766409\n",
      "Testing Error 18759.348497311094\n",
      "--------------------\n",
      "---------- Alpha 0.758 ---------\n",
      "Training Error 13352.223991455368\n",
      "Testing Error 18759.884183705457\n",
      "--------------------\n",
      "---------- Alpha 0.759 ---------\n",
      "Training Error 13353.015474301594\n",
      "Testing Error 18760.418526658603\n",
      "--------------------\n",
      "---------- Alpha 0.76 ---------\n",
      "Training Error 13353.805545979347\n",
      "Testing Error 18760.951529695576\n",
      "--------------------\n",
      "---------- Alpha 0.761 ---------\n",
      "Training Error 13354.594210149691\n",
      "Testing Error 18761.48319632907\n",
      "--------------------\n",
      "---------- Alpha 0.762 ---------\n",
      "Training Error 13355.381470460734\n",
      "Testing Error 18762.013530059656\n",
      "--------------------\n",
      "---------- Alpha 0.763 ---------\n",
      "Training Error 13356.167330547536\n",
      "Testing Error 18762.542534375705\n",
      "--------------------\n",
      "---------- Alpha 0.764 ---------\n",
      "Training Error 13356.951794032248\n",
      "Testing Error 18763.07021275339\n",
      "--------------------\n",
      "---------- Alpha 0.765 ---------\n",
      "Training Error 13357.734864524147\n",
      "Testing Error 18763.596568656958\n",
      "--------------------\n",
      "---------- Alpha 0.766 ---------\n",
      "Training Error 13358.516545619706\n",
      "Testing Error 18764.121605538458\n",
      "--------------------\n",
      "---------- Alpha 0.767 ---------\n",
      "Training Error 13359.296840902625\n",
      "Testing Error 18764.645326838152\n",
      "--------------------\n",
      "---------- Alpha 0.768 ---------\n",
      "Training Error 13360.075753943911\n",
      "Testing Error 18765.16773598429\n",
      "--------------------\n",
      "---------- Alpha 0.769 ---------\n",
      "Training Error 13360.853288301956\n",
      "Testing Error 18765.68883639325\n",
      "--------------------\n",
      "---------- Alpha 0.77 ---------\n",
      "Training Error 13361.632055766186\n",
      "Testing Error 18766.208631469708\n",
      "--------------------\n",
      "---------- Alpha 0.771 ---------\n",
      "Training Error 13362.412752177546\n",
      "Testing Error 18766.727124606532\n",
      "--------------------\n",
      "---------- Alpha 0.772 ---------\n",
      "Training Error 13363.192069823142\n",
      "Testing Error 18767.244319184825\n",
      "--------------------\n",
      "---------- Alpha 0.773 ---------\n",
      "Training Error 13363.970012241198\n",
      "Testing Error 18767.7602185741\n",
      "--------------------\n",
      "---------- Alpha 0.774 ---------\n",
      "Training Error 13364.746582957445\n",
      "Testing Error 18768.274826132358\n",
      "--------------------\n",
      "---------- Alpha 0.775 ---------\n",
      "Training Error 13365.521785485198\n",
      "Testing Error 18768.788145205886\n",
      "--------------------\n",
      "---------- Alpha 0.776 ---------\n",
      "Training Error 13366.295623325426\n",
      "Testing Error 18769.300179129532\n",
      "--------------------\n",
      "---------- Alpha 0.777 ---------\n",
      "Training Error 13367.06809996679\n",
      "Testing Error 18769.81093122677\n",
      "--------------------\n",
      "---------- Alpha 0.778 ---------\n",
      "Training Error 13367.839218885732\n",
      "Testing Error 18770.320404809667\n",
      "--------------------\n",
      "---------- Alpha 0.779 ---------\n",
      "Training Error 13368.608983546488\n",
      "Testing Error 18770.82860317884\n",
      "--------------------\n",
      "---------- Alpha 0.78 ---------\n",
      "Training Error 13369.377397401131\n",
      "Testing Error 18771.3355296237\n",
      "--------------------\n",
      "---------- Alpha 0.781 ---------\n",
      "Training Error 13370.144463889712\n",
      "Testing Error 18771.84118742233\n",
      "--------------------\n",
      "---------- Alpha 0.782 ---------\n",
      "Training Error 13370.910186440226\n",
      "Testing Error 18772.345579841756\n",
      "--------------------\n",
      "---------- Alpha 0.783 ---------\n",
      "Training Error 13371.674568468708\n",
      "Testing Error 18772.848710137743\n",
      "--------------------\n",
      "---------- Alpha 0.784 ---------\n",
      "Training Error 13372.437613379261\n",
      "Testing Error 18773.350581555\n",
      "--------------------\n",
      "---------- Alpha 0.785 ---------\n",
      "Training Error 13373.199324564102\n",
      "Testing Error 18773.851197327076\n",
      "--------------------\n",
      "---------- Alpha 0.786 ---------\n",
      "Training Error 13373.959705403713\n",
      "Testing Error 18774.350560676678\n",
      "--------------------\n",
      "---------- Alpha 0.787 ---------\n",
      "Training Error 13374.718759266734\n",
      "Testing Error 18774.848674815494\n",
      "--------------------\n",
      "---------- Alpha 0.788 ---------\n",
      "Training Error 13375.47648951015\n",
      "Testing Error 18775.345542944255\n",
      "--------------------\n",
      "---------- Alpha 0.789 ---------\n",
      "Training Error 13376.232899479259\n",
      "Testing Error 18775.841168252853\n",
      "--------------------\n",
      "---------- Alpha 0.79 ---------\n",
      "Training Error 13376.987992507788\n",
      "Testing Error 18776.335553920435\n",
      "--------------------\n",
      "---------- Alpha 0.791 ---------\n",
      "Training Error 13377.741771917887\n",
      "Testing Error 18776.828703115247\n",
      "--------------------\n",
      "---------- Alpha 0.792 ---------\n",
      "Training Error 13378.494241020213\n",
      "Testing Error 18777.320618994985\n",
      "--------------------\n",
      "---------- Alpha 0.793 ---------\n",
      "Training Error 13379.245403113995\n",
      "Testing Error 18777.811304706574\n",
      "--------------------\n",
      "---------- Alpha 0.794 ---------\n",
      "Training Error 13379.995261487009\n",
      "Testing Error 18778.300763386178\n",
      "--------------------\n",
      "---------- Alpha 0.795 ---------\n",
      "Training Error 13380.743819415755\n",
      "Testing Error 18778.788998159587\n",
      "--------------------\n",
      "---------- Alpha 0.796 ---------\n",
      "Training Error 13381.49108016537\n",
      "Testing Error 18779.27601214201\n",
      "--------------------\n",
      "---------- Alpha 0.797 ---------\n",
      "Training Error 13382.23704698979\n",
      "Testing Error 18779.761808438107\n",
      "--------------------\n",
      "---------- Alpha 0.798 ---------\n",
      "Training Error 13382.981723131728\n",
      "Testing Error 18780.246390142078\n",
      "--------------------\n",
      "---------- Alpha 0.799 ---------\n",
      "Training Error 13383.72511182276\n",
      "Testing Error 18780.729760337737\n",
      "--------------------\n",
      "---------- Alpha 0.8 ---------\n",
      "Training Error 13384.467216283358\n",
      "Testing Error 18781.211922098653\n",
      "--------------------\n",
      "---------- Alpha 0.801 ---------\n",
      "Training Error 13385.208039722922\n",
      "Testing Error 18781.69287848789\n",
      "--------------------\n",
      "---------- Alpha 0.802 ---------\n",
      "Training Error 13385.947585339894\n",
      "Testing Error 18782.172632558377\n",
      "--------------------\n",
      "---------- Alpha 0.803 ---------\n",
      "Training Error 13386.685856321728\n",
      "Testing Error 18782.65118735281\n",
      "--------------------\n",
      "---------- Alpha 0.804 ---------\n",
      "Training Error 13387.422855844969\n",
      "Testing Error 18783.12854590356\n",
      "--------------------\n",
      "---------- Alpha 0.805 ---------\n",
      "Training Error 13388.158587075342\n",
      "Testing Error 18783.604711233074\n",
      "--------------------\n",
      "---------- Alpha 0.806 ---------\n",
      "Training Error 13388.8930531677\n",
      "Testing Error 18784.079686353514\n",
      "--------------------\n",
      "---------- Alpha 0.807 ---------\n",
      "Training Error 13389.6262572662\n",
      "Testing Error 18784.55347426718\n",
      "--------------------\n",
      "---------- Alpha 0.808 ---------\n",
      "Training Error 13390.363068523415\n",
      "Testing Error 18785.026077966224\n",
      "--------------------\n",
      "---------- Alpha 0.809 ---------\n",
      "Training Error 13391.1004289319\n",
      "Testing Error 18785.49750043273\n",
      "--------------------\n",
      "---------- Alpha 0.81 ---------\n",
      "Training Error 13391.83652827454\n",
      "Testing Error 18785.967744639125\n",
      "--------------------\n",
      "---------- Alpha 0.811 ---------\n",
      "Training Error 13392.571369670526\n",
      "Testing Error 18786.436813547833\n",
      "--------------------\n",
      "---------- Alpha 0.812 ---------\n",
      "Training Error 13393.304956228363\n",
      "Testing Error 18786.904710111332\n",
      "--------------------\n",
      "---------- Alpha 0.813 ---------\n",
      "Training Error 13394.037291046108\n",
      "Testing Error 18787.371437272377\n",
      "--------------------\n",
      "---------- Alpha 0.814 ---------\n",
      "Training Error 13394.768377211316\n",
      "Testing Error 18787.836997964063\n",
      "--------------------\n",
      "---------- Alpha 0.815 ---------\n",
      "Training Error 13395.498217801056\n",
      "Testing Error 18788.301395109618\n",
      "--------------------\n",
      "---------- Alpha 0.816 ---------\n",
      "Training Error 13396.226815882037\n",
      "Testing Error 18788.76463162274\n",
      "--------------------\n",
      "---------- Alpha 0.817 ---------\n",
      "Training Error 13396.95417451057\n",
      "Testing Error 18789.226710407285\n",
      "--------------------\n",
      "---------- Alpha 0.818 ---------\n",
      "Training Error 13397.680296732693\n",
      "Testing Error 18789.687634357757\n",
      "--------------------\n",
      "---------- Alpha 0.819 ---------\n",
      "Training Error 13398.405185584157\n",
      "Testing Error 18790.147406358923\n",
      "--------------------\n",
      "---------- Alpha 0.82 ---------\n",
      "Training Error 13399.128844090483\n",
      "Testing Error 18790.606029286126\n",
      "--------------------\n",
      "---------- Alpha 0.821 ---------\n",
      "Training Error 13399.85127526704\n",
      "Testing Error 18791.063506005277\n",
      "--------------------\n",
      "---------- Alpha 0.822 ---------\n",
      "Training Error 13400.572482119003\n",
      "Testing Error 18791.51983937262\n",
      "--------------------\n",
      "---------- Alpha 0.823 ---------\n",
      "Training Error 13401.29246764152\n",
      "Testing Error 18791.975032235303\n",
      "--------------------\n",
      "---------- Alpha 0.824 ---------\n",
      "Training Error 13402.01123481966\n",
      "Testing Error 18792.42908743098\n",
      "--------------------\n",
      "---------- Alpha 0.825 ---------\n",
      "Training Error 13402.728786628473\n",
      "Testing Error 18792.882007787946\n",
      "--------------------\n",
      "---------- Alpha 0.826 ---------\n",
      "Training Error 13403.445126033102\n",
      "Testing Error 18793.333796125415\n",
      "--------------------\n",
      "---------- Alpha 0.827 ---------\n",
      "Training Error 13404.160255988687\n",
      "Testing Error 18793.784455253044\n",
      "--------------------\n",
      "---------- Alpha 0.828 ---------\n",
      "Training Error 13404.874179440538\n",
      "Testing Error 18794.233987971427\n",
      "--------------------\n",
      "---------- Alpha 0.829 ---------\n",
      "Training Error 13405.586899324177\n",
      "Testing Error 18794.682397072254\n",
      "--------------------\n",
      "---------- Alpha 0.83 ---------\n",
      "Training Error 13406.298418565237\n",
      "Testing Error 18795.12968533775\n",
      "--------------------\n",
      "---------- Alpha 0.831 ---------\n",
      "Training Error 13407.008740079662\n",
      "Testing Error 18795.575855541236\n",
      "--------------------\n",
      "---------- Alpha 0.832 ---------\n",
      "Training Error 13407.723636488981\n",
      "Testing Error 18796.0209104468\n",
      "--------------------\n",
      "---------- Alpha 0.833 ---------\n",
      "Training Error 13408.440953941405\n",
      "Testing Error 18796.46485280979\n",
      "--------------------\n",
      "---------- Alpha 0.834 ---------\n",
      "Training Error 13409.15707131002\n",
      "Testing Error 18796.90768537641\n",
      "--------------------\n",
      "---------- Alpha 0.835 ---------\n",
      "Training Error 13409.87199149633\n",
      "Testing Error 18797.349410883904\n",
      "--------------------\n",
      "---------- Alpha 0.836 ---------\n",
      "Training Error 13410.585717392298\n",
      "Testing Error 18797.79003206072\n",
      "--------------------\n",
      "---------- Alpha 0.837 ---------\n",
      "Training Error 13411.29825188023\n",
      "Testing Error 18798.229551626406\n",
      "--------------------\n",
      "---------- Alpha 0.838 ---------\n",
      "Training Error 13412.009597832912\n",
      "Testing Error 18798.667972291645\n",
      "--------------------\n",
      "---------- Alpha 0.839 ---------\n",
      "Training Error 13412.71975811368\n",
      "Testing Error 18799.105296758436\n",
      "--------------------\n",
      "---------- Alpha 0.84 ---------\n",
      "Training Error 13413.42873557634\n",
      "Testing Error 18799.54152771981\n",
      "--------------------\n",
      "---------- Alpha 0.841 ---------\n",
      "Training Error 13414.136533065304\n",
      "Testing Error 18799.976667860403\n",
      "--------------------\n",
      "---------- Alpha 0.842 ---------\n",
      "Training Error 13414.843153415617\n",
      "Testing Error 18800.41071985588\n",
      "--------------------\n",
      "---------- Alpha 0.843 ---------\n",
      "Training Error 13415.548599452959\n",
      "Testing Error 18800.843686373504\n",
      "--------------------\n",
      "---------- Alpha 0.844 ---------\n",
      "Training Error 13416.252873993708\n",
      "Testing Error 18801.27557007166\n",
      "--------------------\n",
      "---------- Alpha 0.845 ---------\n",
      "Training Error 13416.955979845003\n",
      "Testing Error 18801.706373600406\n",
      "--------------------\n",
      "---------- Alpha 0.846 ---------\n",
      "Training Error 13417.65791980474\n",
      "Testing Error 18802.136099601114\n",
      "--------------------\n",
      "---------- Alpha 0.847 ---------\n",
      "Training Error 13418.358696661624\n",
      "Testing Error 18802.5647507067\n",
      "--------------------\n",
      "---------- Alpha 0.848 ---------\n",
      "Training Error 13419.058313195263\n",
      "Testing Error 18802.992329541717\n",
      "--------------------\n",
      "---------- Alpha 0.849 ---------\n",
      "Training Error 13419.75677217607\n",
      "Testing Error 18803.41883872205\n",
      "--------------------\n",
      "---------- Alpha 0.85 ---------\n",
      "Training Error 13420.454076365437\n",
      "Testing Error 18803.84428085536\n",
      "--------------------\n",
      "---------- Alpha 0.851 ---------\n",
      "Training Error 13421.150228515764\n",
      "Testing Error 18804.26865854094\n",
      "--------------------\n",
      "---------- Alpha 0.852 ---------\n",
      "Training Error 13421.845231370371\n",
      "Testing Error 18804.691974369696\n",
      "--------------------\n",
      "---------- Alpha 0.853 ---------\n",
      "Training Error 13422.539087663698\n",
      "Testing Error 18805.114230924202\n",
      "--------------------\n",
      "---------- Alpha 0.854 ---------\n",
      "Training Error 13423.23180012121\n",
      "Testing Error 18805.535430778917\n",
      "--------------------\n",
      "---------- Alpha 0.855 ---------\n",
      "Training Error 13423.923371459545\n",
      "Testing Error 18805.955576499917\n",
      "--------------------\n",
      "---------- Alpha 0.856 ---------\n",
      "Training Error 13424.613804386428\n",
      "Testing Error 18806.374670645164\n",
      "--------------------\n",
      "---------- Alpha 0.857 ---------\n",
      "Training Error 13425.303101600834\n",
      "Testing Error 18806.792715764394\n",
      "--------------------\n",
      "---------- Alpha 0.858 ---------\n",
      "Training Error 13425.991265792947\n",
      "Testing Error 18807.209714399352\n",
      "--------------------\n",
      "---------- Alpha 0.859 ---------\n",
      "Training Error 13426.678299644218\n",
      "Testing Error 18807.62566908355\n",
      "--------------------\n",
      "---------- Alpha 0.86 ---------\n",
      "Training Error 13427.36420582738\n",
      "Testing Error 18808.04058234245\n",
      "--------------------\n",
      "---------- Alpha 0.861 ---------\n",
      "Training Error 13428.048987006527\n",
      "Testing Error 18808.454456693526\n",
      "--------------------\n",
      "---------- Alpha 0.862 ---------\n",
      "Training Error 13428.732645837144\n",
      "Testing Error 18808.86729464634\n",
      "--------------------\n",
      "---------- Alpha 0.863 ---------\n",
      "Training Error 13429.415184966056\n",
      "Testing Error 18809.279098702296\n",
      "--------------------\n",
      "---------- Alpha 0.864 ---------\n",
      "Training Error 13430.096607031619\n",
      "Testing Error 18809.68987135495\n",
      "--------------------\n",
      "---------- Alpha 0.865 ---------\n",
      "Training Error 13430.776914663606\n",
      "Testing Error 18810.099615089995\n",
      "--------------------\n",
      "---------- Alpha 0.866 ---------\n",
      "Training Error 13431.456110483332\n",
      "Testing Error 18810.508332385296\n",
      "--------------------\n",
      "---------- Alpha 0.867 ---------\n",
      "Training Error 13432.134197103667\n",
      "Testing Error 18810.916025710758\n",
      "--------------------\n",
      "---------- Alpha 0.868 ---------\n",
      "Training Error 13432.81124023097\n",
      "Testing Error 18811.32269752853\n",
      "--------------------\n",
      "---------- Alpha 0.869 ---------\n",
      "Training Error 13433.487824953643\n",
      "Testing Error 18811.728350292968\n",
      "--------------------\n",
      "---------- Alpha 0.87 ---------\n",
      "Training Error 13434.16330769851\n",
      "Testing Error 18812.132986450753\n",
      "--------------------\n",
      "---------- Alpha 0.871 ---------\n",
      "Training Error 13434.837691045153\n",
      "Testing Error 18812.53660844079\n",
      "--------------------\n",
      "---------- Alpha 0.872 ---------\n",
      "Training Error 13435.510977564887\n",
      "Testing Error 18812.9392186944\n",
      "--------------------\n",
      "---------- Alpha 0.873 ---------\n",
      "Training Error 13436.183169820773\n",
      "Testing Error 18813.340819635054\n",
      "--------------------\n",
      "---------- Alpha 0.874 ---------\n",
      "Training Error 13436.854270367634\n",
      "Testing Error 18813.741413678785\n",
      "--------------------\n",
      "---------- Alpha 0.875 ---------\n",
      "Training Error 13437.524281752187\n",
      "Testing Error 18814.141003233955\n",
      "--------------------\n",
      "---------- Alpha 0.876 ---------\n",
      "Training Error 13438.193206512959\n",
      "Testing Error 18814.539590701483\n",
      "--------------------\n",
      "---------- Alpha 0.877 ---------\n",
      "Training Error 13438.861047180391\n",
      "Testing Error 18814.937178474524\n",
      "--------------------\n",
      "---------- Alpha 0.878 ---------\n",
      "Training Error 13439.527806276843\n",
      "Testing Error 18815.33376893896\n",
      "--------------------\n",
      "---------- Alpha 0.879 ---------\n",
      "Training Error 13440.195307648564\n",
      "Testing Error 18815.729364473144\n",
      "--------------------\n",
      "---------- Alpha 0.88 ---------\n",
      "Training Error 13440.864764028669\n",
      "Testing Error 18816.1239674479\n",
      "--------------------\n",
      "---------- Alpha 0.881 ---------\n",
      "Training Error 13441.53314114339\n",
      "Testing Error 18816.517580226755\n",
      "--------------------\n",
      "---------- Alpha 0.882 ---------\n",
      "Training Error 13442.20044149543\n",
      "Testing Error 18816.910205165826\n",
      "--------------------\n",
      "---------- Alpha 0.883 ---------\n",
      "Training Error 13442.866667579576\n",
      "Testing Error 18817.30184461381\n",
      "--------------------\n",
      "---------- Alpha 0.884 ---------\n",
      "Training Error 13443.531821882721\n",
      "Testing Error 18817.692500912162\n",
      "--------------------\n",
      "---------- Alpha 0.885 ---------\n",
      "Training Error 13444.195906883833\n",
      "Testing Error 18818.082176395073\n",
      "--------------------\n",
      "---------- Alpha 0.886 ---------\n",
      "Training Error 13444.858925054037\n",
      "Testing Error 18818.470873389328\n",
      "--------------------\n",
      "---------- Alpha 0.887 ---------\n",
      "Training Error 13445.520878856609\n",
      "Testing Error 18818.858594214584\n",
      "--------------------\n",
      "---------- Alpha 0.888 ---------\n",
      "Training Error 13446.181770747091\n",
      "Testing Error 18819.24534118328\n",
      "--------------------\n",
      "---------- Alpha 0.889 ---------\n",
      "Training Error 13446.841603173227\n",
      "Testing Error 18819.631116600747\n",
      "--------------------\n",
      "---------- Alpha 0.89 ---------\n",
      "Training Error 13447.50167343754\n",
      "Testing Error 18820.015922764953\n",
      "--------------------\n",
      "---------- Alpha 0.891 ---------\n",
      "Training Error 13448.16337563556\n",
      "Testing Error 18820.399761967063\n",
      "--------------------\n",
      "---------- Alpha 0.892 ---------\n",
      "Training Error 13448.824019094476\n",
      "Testing Error 18820.78263649082\n",
      "--------------------\n",
      "---------- Alpha 0.893 ---------\n",
      "Training Error 13449.483606246458\n",
      "Testing Error 18821.164548613113\n",
      "--------------------\n",
      "---------- Alpha 0.894 ---------\n",
      "Training Error 13450.142139516063\n",
      "Testing Error 18821.545500603752\n",
      "--------------------\n",
      "---------- Alpha 0.895 ---------\n",
      "Training Error 13450.799621320159\n",
      "Testing Error 18821.9254947254\n",
      "--------------------\n",
      "---------- Alpha 0.896 ---------\n",
      "Training Error 13451.456054068098\n",
      "Testing Error 18822.304533234055\n",
      "--------------------\n",
      "---------- Alpha 0.897 ---------\n",
      "Training Error 13452.111440161629\n",
      "Testing Error 18822.68261837837\n",
      "--------------------\n",
      "---------- Alpha 0.898 ---------\n",
      "Training Error 13452.765781994985\n",
      "Testing Error 18823.059752400353\n",
      "--------------------\n",
      "---------- Alpha 0.899 ---------\n",
      "Training Error 13453.419081954888\n",
      "Testing Error 18823.435937535076\n",
      "--------------------\n",
      "---------- Alpha 0.9 ---------\n",
      "Training Error 13454.07134242058\n",
      "Testing Error 18823.811176010524\n",
      "--------------------\n",
      "---------- Alpha 0.901 ---------\n",
      "Training Error 13454.722565763917\n",
      "Testing Error 18824.185470048105\n",
      "--------------------\n",
      "---------- Alpha 0.902 ---------\n",
      "Training Error 13455.373631026638\n",
      "Testing Error 18824.55882186228\n",
      "--------------------\n",
      "---------- Alpha 0.903 ---------\n",
      "Training Error 13456.024665354136\n",
      "Testing Error 18824.93123366077\n",
      "--------------------\n",
      "---------- Alpha 0.904 ---------\n",
      "Training Error 13456.674668846927\n",
      "Testing Error 18825.302707644416\n",
      "--------------------\n",
      "---------- Alpha 0.905 ---------\n",
      "Training Error 13457.323643846112\n",
      "Testing Error 18825.673246007413\n",
      "--------------------\n",
      "---------- Alpha 0.906 ---------\n",
      "Training Error 13457.971592685517\n",
      "Testing Error 18826.04285093733\n",
      "--------------------\n",
      "---------- Alpha 0.907 ---------\n",
      "Training Error 13458.618517691688\n",
      "Testing Error 18826.411524614814\n",
      "--------------------\n",
      "---------- Alpha 0.908 ---------\n",
      "Training Error 13459.264421183978\n",
      "Testing Error 18826.77926921398\n",
      "--------------------\n",
      "---------- Alpha 0.909 ---------\n",
      "Training Error 13459.909305474543\n",
      "Testing Error 18827.14608690246\n",
      "--------------------\n",
      "---------- Alpha 0.91 ---------\n",
      "Training Error 13460.553172868333\n",
      "Testing Error 18827.511979840972\n",
      "--------------------\n",
      "---------- Alpha 0.911 ---------\n",
      "Training Error 13461.196025663205\n",
      "Testing Error 18827.87695018385\n",
      "--------------------\n",
      "---------- Alpha 0.912 ---------\n",
      "Training Error 13461.837866149885\n",
      "Testing Error 18828.241000078786\n",
      "--------------------\n",
      "---------- Alpha 0.913 ---------\n",
      "Training Error 13462.47869661201\n",
      "Testing Error 18828.60413166702\n",
      "--------------------\n",
      "---------- Alpha 0.914 ---------\n",
      "Training Error 13463.118519326199\n",
      "Testing Error 18828.96634708326\n",
      "--------------------\n",
      "---------- Alpha 0.915 ---------\n",
      "Training Error 13463.758822888783\n",
      "Testing Error 18829.327648455663\n",
      "--------------------\n",
      "---------- Alpha 0.916 ---------\n",
      "Training Error 13464.404068610698\n",
      "Testing Error 18829.688037906013\n",
      "--------------------\n",
      "---------- Alpha 0.917 ---------\n",
      "Training Error 13465.048305620661\n",
      "Testing Error 18830.047517549527\n",
      "--------------------\n",
      "---------- Alpha 0.918 ---------\n",
      "Training Error 13465.69153618151\n",
      "Testing Error 18830.40608949518\n",
      "--------------------\n",
      "---------- Alpha 0.919 ---------\n",
      "Training Error 13466.333762549164\n",
      "Testing Error 18830.763755845503\n",
      "--------------------\n",
      "---------- Alpha 0.92 ---------\n",
      "Training Error 13466.974986972553\n",
      "Testing Error 18831.120518696654\n",
      "--------------------\n",
      "---------- Alpha 0.921 ---------\n",
      "Training Error 13467.615211693768\n",
      "Testing Error 18831.476380138432\n",
      "--------------------\n",
      "---------- Alpha 0.922 ---------\n",
      "Training Error 13468.254438947957\n",
      "Testing Error 18831.83134225429\n",
      "--------------------\n",
      "---------- Alpha 0.923 ---------\n",
      "Training Error 13468.892670963522\n",
      "Testing Error 18832.185407121575\n",
      "--------------------\n",
      "---------- Alpha 0.924 ---------\n",
      "Training Error 13469.529909961962\n",
      "Testing Error 18832.538576811166\n",
      "--------------------\n",
      "---------- Alpha 0.925 ---------\n",
      "Training Error 13470.166158158054\n",
      "Testing Error 18832.890853387886\n",
      "--------------------\n",
      "---------- Alpha 0.926 ---------\n",
      "Training Error 13470.801417759767\n",
      "Testing Error 18833.242238910178\n",
      "--------------------\n",
      "---------- Alpha 0.927 ---------\n",
      "Training Error 13471.435690968325\n",
      "Testing Error 18833.59273543037\n",
      "--------------------\n",
      "---------- Alpha 0.928 ---------\n",
      "Training Error 13472.06897997829\n",
      "Testing Error 18833.942344994666\n",
      "--------------------\n",
      "---------- Alpha 0.929 ---------\n",
      "Training Error 13472.701286977499\n",
      "Testing Error 18834.29106964301\n",
      "--------------------\n",
      "---------- Alpha 0.93 ---------\n",
      "Training Error 13473.332614147137\n",
      "Testing Error 18834.638911409336\n",
      "--------------------\n",
      "---------- Alpha 0.931 ---------\n",
      "Training Error 13473.962963661766\n",
      "Testing Error 18834.98587232144\n",
      "--------------------\n",
      "---------- Alpha 0.932 ---------\n",
      "Training Error 13474.59233768935\n",
      "Testing Error 18835.331954401063\n",
      "--------------------\n",
      "---------- Alpha 0.933 ---------\n",
      "Training Error 13475.220738391256\n",
      "Testing Error 18835.67715966389\n",
      "--------------------\n",
      "---------- Alpha 0.934 ---------\n",
      "Training Error 13475.848167922299\n",
      "Testing Error 18836.02149011959\n",
      "--------------------\n",
      "---------- Alpha 0.935 ---------\n",
      "Training Error 13476.474628430748\n",
      "Testing Error 18836.364947771694\n",
      "--------------------\n",
      "---------- Alpha 0.936 ---------\n",
      "Training Error 13477.1001220584\n",
      "Testing Error 18836.707534618\n",
      "--------------------\n",
      "---------- Alpha 0.937 ---------\n",
      "Training Error 13477.72465094057\n",
      "Testing Error 18837.049252650133\n",
      "--------------------\n",
      "---------- Alpha 0.938 ---------\n",
      "Training Error 13478.348217206072\n",
      "Testing Error 18837.39010385384\n",
      "--------------------\n",
      "---------- Alpha 0.939 ---------\n",
      "Training Error 13478.970822977355\n",
      "Testing Error 18837.730090209086\n",
      "--------------------\n",
      "---------- Alpha 0.94 ---------\n",
      "Training Error 13479.592470370406\n",
      "Testing Error 18838.06921368973\n",
      "--------------------\n",
      "---------- Alpha 0.941 ---------\n",
      "Training Error 13480.213161494887\n",
      "Testing Error 18838.40747626396\n",
      "--------------------\n",
      "---------- Alpha 0.942 ---------\n",
      "Training Error 13480.832898454068\n",
      "Testing Error 18838.74487989399\n",
      "--------------------\n",
      "---------- Alpha 0.943 ---------\n",
      "Training Error 13481.451683344869\n",
      "Testing Error 18839.081426536184\n",
      "--------------------\n",
      "---------- Alpha 0.944 ---------\n",
      "Training Error 13482.069518257966\n",
      "Testing Error 18839.417118141217\n",
      "--------------------\n",
      "---------- Alpha 0.945 ---------\n",
      "Training Error 13482.688582359995\n",
      "Testing Error 18839.751956653923\n",
      "--------------------\n",
      "---------- Alpha 0.946 ---------\n",
      "Training Error 13483.30712721091\n",
      "Testing Error 18840.08594401342\n",
      "--------------------\n",
      "---------- Alpha 0.947 ---------\n",
      "Training Error 13483.924721093015\n",
      "Testing Error 18840.419082153003\n",
      "--------------------\n",
      "---------- Alpha 0.948 ---------\n",
      "Training Error 13484.541366091124\n",
      "Testing Error 18840.751373000316\n",
      "--------------------\n",
      "---------- Alpha 0.949 ---------\n",
      "Training Error 13485.157064283752\n",
      "Testing Error 18841.082818477356\n",
      "--------------------\n",
      "---------- Alpha 0.95 ---------\n",
      "Training Error 13485.771817743183\n",
      "Testing Error 18841.41342050025\n",
      "--------------------\n",
      "---------- Alpha 0.951 ---------\n",
      "Training Error 13486.385628535543\n",
      "Testing Error 18841.74318097973\n",
      "--------------------\n",
      "---------- Alpha 0.952 ---------\n",
      "Training Error 13486.99849872076\n",
      "Testing Error 18842.07210182077\n",
      "--------------------\n",
      "---------- Alpha 0.953 ---------\n",
      "Training Error 13487.6104303526\n",
      "Testing Error 18842.400184922666\n",
      "--------------------\n",
      "---------- Alpha 0.954 ---------\n",
      "Training Error 13488.221425478707\n",
      "Testing Error 18842.72743217921\n",
      "--------------------\n",
      "---------- Alpha 0.955 ---------\n",
      "Training Error 13488.831486140643\n",
      "Testing Error 18843.053845478702\n",
      "--------------------\n",
      "---------- Alpha 0.956 ---------\n",
      "Training Error 13489.440614373847\n",
      "Testing Error 18843.379426703752\n",
      "--------------------\n",
      "---------- Alpha 0.957 ---------\n",
      "Training Error 13490.048812207746\n",
      "Testing Error 18843.704177731546\n",
      "--------------------\n",
      "---------- Alpha 0.958 ---------\n",
      "Training Error 13490.656081665655\n",
      "Testing Error 18844.028100433592\n",
      "--------------------\n",
      "---------- Alpha 0.959 ---------\n",
      "Training Error 13491.262424764964\n",
      "Testing Error 18844.351196676187\n",
      "--------------------\n",
      "---------- Alpha 0.96 ---------\n",
      "Training Error 13491.86784351703\n",
      "Testing Error 18844.673468319947\n",
      "--------------------\n",
      "---------- Alpha 0.961 ---------\n",
      "Training Error 13492.472339927235\n",
      "Testing Error 18844.994917220174\n",
      "--------------------\n",
      "---------- Alpha 0.962 ---------\n",
      "Training Error 13493.075915995036\n",
      "Testing Error 18845.31554522661\n",
      "--------------------\n",
      "---------- Alpha 0.963 ---------\n",
      "Training Error 13493.678573713947\n",
      "Testing Error 18845.635354183716\n",
      "--------------------\n",
      "---------- Alpha 0.964 ---------\n",
      "Training Error 13494.280315071606\n",
      "Testing Error 18845.954345930546\n",
      "--------------------\n",
      "---------- Alpha 0.965 ---------\n",
      "Training Error 13494.881142049755\n",
      "Testing Error 18846.27252230073\n",
      "--------------------\n",
      "---------- Alpha 0.966 ---------\n",
      "Training Error 13495.481056624283\n",
      "Testing Error 18846.589885122565\n",
      "--------------------\n",
      "---------- Alpha 0.967 ---------\n",
      "Training Error 13496.08006076524\n",
      "Testing Error 18846.90643621908\n",
      "--------------------\n",
      "---------- Alpha 0.968 ---------\n",
      "Training Error 13496.678156436905\n",
      "Testing Error 18847.222177408028\n",
      "--------------------\n",
      "---------- Alpha 0.969 ---------\n",
      "Training Error 13497.27534559772\n",
      "Testing Error 18847.53711050175\n",
      "--------------------\n",
      "---------- Alpha 0.97 ---------\n",
      "Training Error 13497.871630200358\n",
      "Testing Error 18847.85123730746\n",
      "--------------------\n",
      "---------- Alpha 0.971 ---------\n",
      "Training Error 13498.467012191788\n",
      "Testing Error 18848.164559626926\n",
      "--------------------\n",
      "---------- Alpha 0.972 ---------\n",
      "Training Error 13499.061493513209\n",
      "Testing Error 18848.477079256903\n",
      "--------------------\n",
      "---------- Alpha 0.973 ---------\n",
      "Training Error 13499.655076100174\n",
      "Testing Error 18848.78879798893\n",
      "--------------------\n",
      "---------- Alpha 0.974 ---------\n",
      "Training Error 13500.247761882494\n",
      "Testing Error 18849.099717609184\n",
      "--------------------\n",
      "---------- Alpha 0.975 ---------\n",
      "Training Error 13500.83955278434\n",
      "Testing Error 18849.40983989878\n",
      "--------------------\n",
      "---------- Alpha 0.976 ---------\n",
      "Training Error 13501.430450724258\n",
      "Testing Error 18849.719166633684\n",
      "--------------------\n",
      "---------- Alpha 0.977 ---------\n",
      "Training Error 13502.020457615195\n",
      "Testing Error 18850.027699584753\n",
      "--------------------\n",
      "---------- Alpha 0.978 ---------\n",
      "Training Error 13502.609575364439\n",
      "Testing Error 18850.33544051769\n",
      "--------------------\n",
      "---------- Alpha 0.979 ---------\n",
      "Training Error 13503.197805873739\n",
      "Testing Error 18850.642391193058\n",
      "--------------------\n",
      "---------- Alpha 0.98 ---------\n",
      "Training Error 13503.785151039305\n",
      "Testing Error 18850.948553366496\n",
      "--------------------\n",
      "---------- Alpha 0.981 ---------\n",
      "Training Error 13504.371612751811\n",
      "Testing Error 18851.253928788476\n",
      "--------------------\n",
      "---------- Alpha 0.982 ---------\n",
      "Training Error 13504.957192896354\n",
      "Testing Error 18851.558519204344\n",
      "--------------------\n",
      "---------- Alpha 0.983 ---------\n",
      "Training Error 13505.541893352633\n",
      "Testing Error 18851.862326354676\n",
      "--------------------\n",
      "---------- Alpha 0.984 ---------\n",
      "Training Error 13506.12571599481\n",
      "Testing Error 18852.165351974803\n",
      "--------------------\n",
      "---------- Alpha 0.985 ---------\n",
      "Training Error 13506.708662691606\n",
      "Testing Error 18852.46759779521\n",
      "--------------------\n",
      "---------- Alpha 0.986 ---------\n",
      "Training Error 13507.29073530634\n",
      "Testing Error 18852.769065541306\n",
      "--------------------\n",
      "---------- Alpha 0.987 ---------\n",
      "Training Error 13507.87193569689\n",
      "Testing Error 18853.06975693382\n",
      "--------------------\n",
      "---------- Alpha 0.988 ---------\n",
      "Training Error 13508.454451464238\n",
      "Testing Error 18853.369673688187\n",
      "--------------------\n",
      "---------- Alpha 0.989 ---------\n",
      "Training Error 13509.036121647483\n",
      "Testing Error 18853.668817515103\n",
      "--------------------\n",
      "---------- Alpha 0.99 ---------\n",
      "Training Error 13509.616922288467\n",
      "Testing Error 18853.96719012041\n",
      "--------------------\n",
      "---------- Alpha 0.991 ---------\n",
      "Training Error 13510.19685523041\n",
      "Testing Error 18854.264793205086\n",
      "--------------------\n",
      "---------- Alpha 0.992 ---------\n",
      "Training Error 13510.775922311195\n",
      "Testing Error 18854.56162846512\n",
      "--------------------\n",
      "---------- Alpha 0.993 ---------\n",
      "Training Error 13511.354125363398\n",
      "Testing Error 18854.85769759178\n",
      "--------------------\n",
      "---------- Alpha 0.994 ---------\n",
      "Training Error 13511.931466214308\n",
      "Testing Error 18855.153002271494\n",
      "--------------------\n",
      "---------- Alpha 0.995 ---------\n",
      "Training Error 13512.507946685917\n",
      "Testing Error 18855.447544185834\n",
      "--------------------\n",
      "---------- Alpha 0.996 ---------\n",
      "Training Error 13513.08356859497\n",
      "Testing Error 18855.74132501159\n",
      "--------------------\n",
      "---------- Alpha 0.997 ---------\n",
      "Training Error 13513.65833375302\n",
      "Testing Error 18856.034346420867\n",
      "--------------------\n",
      "---------- Alpha 0.998 ---------\n",
      "Training Error 13514.232243966344\n",
      "Testing Error 18856.32661008091\n",
      "--------------------\n",
      "---------- Alpha 0.999 ---------\n",
      "Training Error 13514.805301036036\n",
      "Testing Error 18856.618117654332\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "err = []\n",
    "for i in W:\n",
    "    rr = Ridge(alpha=i)\n",
    "    print(\"----------\",\"Alpha\",i,\"---------\")\n",
    "    tr_err = reg(rr)\n",
    "    err.append(tr_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09c7d821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x29066aab760>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(W,err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962b84a0",
   "metadata": {},
   "source": [
    "# Train the selected regularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13da3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = Ridge(alpha=0.011)\n",
    "model = rr.fit(Xnew,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "381119e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.011)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30d86edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
       "       'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
       "       ...\n",
       "       'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD',\n",
       "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
       "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
       "       'SaleCondition_Partial'],\n",
       "      dtype='object', length=297)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335aa7c",
   "metadata": {},
   "source": [
    "# Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96841f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "061fd389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
       "       'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
       "       ...\n",
       "       'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD',\n",
       "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
       "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
       "       'SaleCondition_Partial'],\n",
       "      dtype='object', length=297)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b191648",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ['Condition2_RRAe', 'Condition2_RRAn', 'Condition2_RRNn', 'HouseStyle_2.5Fin', 'RoofMatl_ClyTile', 'RoofMatl_Membran', 'RoofMatl_Metal', 'RoofMatl_Roll', 'Exterior1st_ImStucc', 'Exterior1st_Stone', 'Exterior2nd_Other', 'Heating_Floor', 'Heating_OthW', 'Electrical_Mix', 'GarageQual_Ex', 'PoolQC_Fa', 'MiscFeature_TenC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e012f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in  r:\n",
    "    xtest[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3490402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfinal = xtest[Xnew.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cca99d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final = model.predict(xfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a39d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub = test[[\"Id\"]]\n",
    "final_sub[[\"SalePrice\"]]= model.predict(xfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bca3740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>116568.477475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>155365.524491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>193317.746596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>200669.835028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>203104.928905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>81719.069353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>77474.675248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>187699.370554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>115518.451966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>228569.096553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  116568.477475\n",
       "1     1462  155365.524491\n",
       "2     1463  193317.746596\n",
       "3     1464  200669.835028\n",
       "4     1465  203104.928905\n",
       "...    ...            ...\n",
       "1454  2915   81719.069353\n",
       "1455  2916   77474.675248\n",
       "1456  2917  187699.370554\n",
       "1457  2918  115518.451966\n",
       "1458  2919  228569.096553\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41dffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d65933d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
